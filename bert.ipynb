{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is Cybersecurity?...\n",
      "Tokens: ['[CLS]', 'what', 'is', 'cyber', '##se', '##cu', '##rity', '?', '[SEP]', 'cyber', '##se', '##cu', '##rity', 'is', 'the', 'practice', 'of', 'protecting', 'systems', ',', 'networks', ',', 'and', 'programs', 'from', 'digital', 'attacks', ',', 'theft', ',', 'or', 'damage', '.', 'these', 'cyber', '##att', '##ack', '##s', 'usually', 'aim', 'to', 'access', ',', 'alter', ',', 'or', 'destroy', 'sensitive', 'information', ',', 'ex', '##tort', 'money', ',', 'or', 'disrupt', 'normal', 'business', 'operations', '.', 'key', 'components', 'include', ':', '-', 'network', 'security', ':', 'protecting', 'network', 'integrity', 'and', 'data', '.', '-', 'application', 'security', ':', 'securing', 'applications', 'by', 'identifying', 'vu', '##ln', '##era', '[SEP]']...\n",
      "Token IDs: [101, 2054, 2003, 16941, 3366, 10841, 15780, 1029, 102, 16941, 3366, 10841, 15780, 2003, 1996, 3218, 1997, 8650, 3001, 1010, 6125, 1010, 1998, 3454, 2013, 3617, 4491, 1010, 11933, 1010, 2030, 4053, 1012, 2122, 16941, 19321, 8684, 2015, 2788, 6614, 2000, 3229, 1010, 11477, 1010, 2030, 6033, 7591, 2592, 1010, 4654, 25485, 2769, 1010, 2030, 23217, 3671, 2449, 3136, 1012, 3145, 6177, 2421, 1024, 1011, 2897, 3036, 1024, 8650, 2897, 11109, 1998, 2951, 1012, 1011, 4646, 3036, 1024, 12329, 5097, 2011, 12151, 24728, 19666, 6906, 102]...\n",
      "\n",
      "\n",
      "Token shape for sentence is (1, 86)\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "\n",
      "Question: What is Malware?...\n",
      "Tokens: ['[CLS]', 'what', 'is', 'mal', '##ware', '?', '[SEP]', 'mal', '##ware', ',', 'short', 'for', 'malicious', 'software', ',', 'refers', 'to', 'any', 'software', 'designed', 'to', 'cause', 'harm', 'to', 'a', 'computer', ',', 'network', ',', 'or', 'server', '.', 'it', 'is', 'used', 'by', 'attackers', 'to', 'steal', 'data', ',', 'spy', 'on', 'users', ',', 'or', 'damage', 'systems', '.', 'types', 'of', 'mal', '##ware', 'include', ':', '-', 'viruses', ':', 'in', '##fect', 'programs', 'and', 'replicate', '.', '-', 'worms', ':', 'spread', 'independently', 'across', 'networks', '.', '-', 'trojan', 'horses', ':', 'disguised', 'as', 'legitimate', 'software', 'but', 'deliver', 'malicious', 'payload', '##s', '[SEP]']...\n",
      "Token IDs: [101, 2054, 2003, 15451, 8059, 1029, 102, 15451, 8059, 1010, 2460, 2005, 24391, 4007, 1010, 5218, 2000, 2151, 4007, 2881, 2000, 3426, 7386, 2000, 1037, 3274, 1010, 2897, 1010, 2030, 8241, 1012, 2009, 2003, 2109, 2011, 17857, 2000, 8954, 2951, 1010, 8645, 2006, 5198, 1010, 2030, 4053, 3001, 1012, 4127, 1997, 15451, 8059, 2421, 1024, 1011, 18191, 1024, 1999, 25969, 3454, 1998, 28024, 1012, 1011, 16253, 1024, 3659, 9174, 2408, 6125, 1012, 1011, 23445, 5194, 1024, 17330, 2004, 11476, 4007, 2021, 8116, 24391, 18093, 2015, 102]...\n",
      "\n",
      "\n",
      "Token shape for sentence is (1, 86)\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "\n",
      "Question: What is Phishing?...\n",
      "Tokens: ['[CLS]', 'what', 'is', 'phi', '##shing', '?', '[SEP]', 'phi', '##shing', 'is', 'a', 'type', 'of', 'cyber', '##att', '##ack', 'where', 'attackers', 'imp', '##erson', '##ate', 'legitimate', 'entities', 'to', 'trick', 'individuals', 'into', 'revealing', 'sensitive', 'information', 'such', 'as', 'user', '##name', '##s', ',', 'password', '##s', ',', 'or', 'financial', 'details', '.', 'phi', '##shing', 'typically', 'occurs', 'through', 'dec', '##eptive', 'emails', ',', 'websites', ',', 'or', 'messages', 'that', 'appear', 'to', 'come', 'from', 'trusted', 'sources', '.', 'common', 'types', 'of', 'phi', '##shing', 'attacks', 'include', ':', '-', 'spear', 'phi', '##shing', ':', 'targeted', 'attacks', 'aimed', 'at', 'specific', 'individuals', 'or', 'organizations', '[SEP]']...\n",
      "Token IDs: [101, 2054, 2003, 13569, 12227, 1029, 102, 13569, 12227, 2003, 1037, 2828, 1997, 16941, 19321, 8684, 2073, 17857, 17727, 18617, 3686, 11476, 11422, 2000, 7577, 3633, 2046, 8669, 7591, 2592, 2107, 2004, 5310, 18442, 2015, 1010, 20786, 2015, 1010, 2030, 3361, 4751, 1012, 13569, 12227, 4050, 5158, 2083, 11703, 22048, 22028, 1010, 11744, 1010, 2030, 7696, 2008, 3711, 2000, 2272, 2013, 9480, 4216, 1012, 2691, 4127, 1997, 13569, 12227, 4491, 2421, 1024, 1011, 12341, 13569, 12227, 1024, 9416, 4491, 6461, 2012, 3563, 3633, 2030, 4411, 102]...\n",
      "\n",
      "\n",
      "Token shape for sentence is (1, 86)\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "long_sentences = [\n",
    "    [\n",
    "        \"What is Cybersecurity?\",\n",
    "        \"Cybersecurity is the practice of protecting systems, networks, and programs from digital attacks, theft, or damage. These cyberattacks usually aim to access, alter, or destroy sensitive information, extort money, or disrupt normal business operations. Key components include:\\n\"\n",
    "        \"- Network Security: Protecting network integrity and data.\\n\"\n",
    "        \"- Application Security: Securing applications by identifying vulnerabilities.\\n\"\n",
    "        \"- Information Security: Ensuring data privacy and integrity.\\n\"\n",
    "        \"- Operational Security: Managing data handling and protection practices.\\n\"\n",
    "        \"Methods such as firewalls, encryption, antivirus software, and multi-factor authentication (MFA) are employed to mitigate cyber threats.\"\n",
    "    ],\n",
    "    [\n",
    "        \"What is Malware?\",\n",
    "        \"Malware, short for malicious software, refers to any software designed to cause harm to a computer, network, or server. It is used by attackers to steal data, spy on users, or damage systems. Types of malware include:\\n\"\n",
    "        \"- Viruses: Infect programs and replicate.\\n\"\n",
    "        \"- Worms: Spread independently across networks.\\n\"\n",
    "        \"- Trojan Horses: Disguised as legitimate software but deliver malicious payloads.\\n\"\n",
    "        \"- Ransomware: Encrypts data and demands payment for decryption.\\n\"\n",
    "        \"- Spyware: Collects and transmits user data secretly.\\n\"\n",
    "        \"- Adware: Shows unwanted ads and may track user data.\\n\"\n",
    "        \"Entry points include infected websites, email attachments, and social engineering.\"\n",
    "    ],\n",
    "    [\n",
    "    \"What is Phishing?\",\n",
    "    \"Phishing is a type of cyberattack where attackers impersonate legitimate entities to trick individuals into revealing sensitive information such as usernames, passwords, or financial details. Phishing typically occurs through deceptive emails, websites, or messages that appear to come from trusted sources.\\n\"\n",
    "    \"Common types of phishing attacks include:\\n\"\n",
    "    \"- Spear Phishing: Targeted attacks aimed at specific individuals or organizations.\\n\"\n",
    "    \"- Whaling: Phishing attempts directed at high-profile targets like executives or senior management.\\n\"\n",
    "    \"- Smishing: Phishing conducted through SMS text messages.\\n\"\n",
    "    \"- Vishing: Voice-based phishing scams.\\n\"\n",
    "    \"Phishing is often identified by suspicious links, urgent requests for personal information, and poor grammar in communications. Users can protect themselves by scrutinizing sender details, avoiding clicking on unverified links, and enabling multi-factor authentication.\"\n",
    "]\n",
    "]\n",
    "ma=86\n",
    "l=sorted(long_sentences,key=len,reverse=True)\n",
    "max_length=ma\n",
    "TOKEN_IDS=[]\n",
    "i=0\n",
    "SEGMENT_IDS=[]\n",
    "for sentence in long_sentences:\n",
    "    encoded_input = tokenizer(\n",
    "        sentence[0],sentence[1],\n",
    "        max_length=max_length,      \n",
    "        truncation=True,     \n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    tokens = tokenizer.convert_ids_to_tokens(encoded_input[\"input_ids\"])\n",
    "    \n",
    "    print(f\"Question: {sentence[0][:]}...\")  \n",
    "#     print(f\"Answer:{sentence[1]:[:]}...\")\n",
    "    print(f\"Tokens: {tokens}...\")       \n",
    "    print(f\"Token IDs: {encoded_input['input_ids']}...\")\n",
    "    print(\"\\n\")\n",
    "#     print(\"Length of the sentence is\",len(sentence[0].split(\" \")))\n",
    "    print(\"Token shape for sentence is\",np.array([tokens]).shape)\n",
    "#     print(\"Length of Encoded Input of this sentence is\",len(encoded_input['input_ids'][:50]))\n",
    "    print(\"\\n\")\n",
    "    print(\"*********************************************************\\n\")\n",
    "    TOKEN_IDS.append(np.array(encoded_input['input_ids']))\n",
    "    SEGMENT_IDS.append(np.array([i for j in range(36)]))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Complete Positional IDs:\n",
      " tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "         54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "         72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85],\n",
      "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "         54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "         72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85],\n",
      "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "         54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "         72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85]])\n",
      "Shapes are: \n",
      "********************************************\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85])\n",
      "(1, 86)\n",
      "********************************************\n",
      "********************************************\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85])\n",
      "(1, 86)\n",
      "********************************************\n",
      "********************************************\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85])\n",
      "(1, 86)\n",
      "********************************************\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def generate_positional_ids(sentences, max_length):\n",
    "    \n",
    "    positional_ids = torch.arange(max_length).unsqueeze(0).expand(len(sentences), -1)\n",
    "    \n",
    "    return positional_ids\n",
    "\n",
    "# Example usage\n",
    "max_length=86\n",
    "  # Specify the maximum length\n",
    "positional_ids = generate_positional_ids(long_sentences, max_length)\n",
    "\n",
    "print(\" Complete Positional IDs:\\n\", positional_ids)\n",
    "print(\"Shapes are: \")\n",
    "POSITIONAL_IDS=[]\n",
    "for tensors in positional_ids:\n",
    "    print(\"********************************************\")\n",
    "    print(tensors)\n",
    "    print(np.array([tensors]).shape)\n",
    "    print(\"********************************************\")\n",
    "    POSITIONAL_IDS.append(np.array(tensors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_IDS=np.array(TOKEN_IDS)\n",
    "POSITIONAL_IDS=np.array(POSITIONAL_IDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 86)\n",
      "(3, 86)\n"
     ]
    }
   ],
   "source": [
    "print(TOKEN_IDS.shape)\n",
    "# print(SEGMENT_IDS.shape)\n",
    "print(POSITIONAL_IDS.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 86)\n"
     ]
    }
   ],
   "source": [
    "combined_ids=TOKEN_IDS+POSITIONAL_IDS\n",
    "print(combined_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  101,  2055,  2005, 16944,  3370, 10846, 15786,  1036,   110,\n",
       "        16950,  3376, 10852, 15792,  2016,  2010,  3233,  2013,  8667,\n",
       "         3019,  1029,  6145,  1031,  2020,  3477,  2037,  3642,  4517,\n",
       "         1037, 11961,  1039,  2060,  4084,  1044,  2155, 16975, 19356,\n",
       "         8720,  2052,  2826,  6653,  2040,  3270,  1052, 11520,  1054,\n",
       "         2075,  6079,  7638,  2640,  1059,  4704, 25536,  2821,  1063,\n",
       "         2084, 23272,  3727,  2506,  3194,  1071,  3205,  6238,  2483,\n",
       "         1087,  1075,  2962,  3102,  1091,  8718,  2966, 11179,  2069,\n",
       "         3023,  1085,  1085,  4721,  3112,  1101, 12407,  5176,  2091,\n",
       "        12232, 24810, 19749,  6990,   187],\n",
       "       [  101,  2055,  2005, 15454,  8063,  1034,   108, 15458,  8067,\n",
       "         1019,  2470,  2016, 24403,  4020,  1024,  5233,  2016,  2168,\n",
       "         4025,  2900,  2020,  3447,  7408,  2023,  1061,  3299,  1036,\n",
       "         2924,  1038,  2059,  8271,  1043,  2041,  2036,  2143,  2046,\n",
       "        17893,  2037,  8992,  2990,  1050,  8686,  2048,  5241,  1054,\n",
       "         2075,  4099,  3048,  1060,  4176,  2047, 15502,  8111,  2474,\n",
       "         1078,  1066, 18247,  1081,  2057, 26028,  3514,  2059, 28086,\n",
       "         1075,  1075, 16318,  1090,  3726,  9242,  2477,  6195,  1083,\n",
       "         1083, 23518,  5268,  1099, 17406,  2081, 11554,  4086,  2101,\n",
       "         8197, 24473, 18176,  2099,   187],\n",
       "       [  101,  2055,  2005, 13572, 12231,  1034,   108, 13576, 12235,\n",
       "         2012,  1047,  2839,  2009, 16954, 19335,  8699,  2089, 17874,\n",
       "        17745, 18636,  3706, 11497, 11444,  2023,  7601,  3658,  2072,\n",
       "         8696,  7619,  2621,  2137,  2035,  5342, 18475,  2049,  1045,\n",
       "        20822,  2052,  1048,  2069,  3401,  4792,  1054, 13612, 12271,\n",
       "         4095,  5204,  2130, 11751, 22097, 22078,  1061, 11796,  1063,\n",
       "         2084,  7751,  2064,  3768,  2058,  2331,  2073,  9541,  4278,\n",
       "         1075,  2755,  4192,  2063, 13636, 12295,  4560,  2491,  1095,\n",
       "         1083, 12414, 13643, 12302,  1100,  9493,  4569,  6540,  2092,\n",
       "         3644,  3715,  2113,  4495,   187]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Embeddings Shape: torch.Size([3, 86, 768])\n",
      "\n",
      "Token Embeddings for Sentence:\n",
      " 0 tensor([[-1.3173, -0.4889, -2.0296,  ..., -1.2706, -0.0596,  0.0905],\n",
      "        [ 0.1539, -0.1608,  0.7088,  ..., -0.0658,  0.5019, -2.0494],\n",
      "        [ 1.1148,  0.3157, -0.9515,  ..., -0.1460,  0.2515, -0.2113],\n",
      "        ...,\n",
      "        [ 0.4355,  0.0764, -1.8080,  ...,  0.7615,  0.8738,  0.4637],\n",
      "        [-0.1186,  1.3766,  0.8951,  ..., -0.1377, -1.4444,  1.6697],\n",
      "        [ 1.4173,  1.0788,  0.5447,  ...,  0.0247,  0.4963,  0.2345]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Shape of the tensor:  torch.Size([86, 768])\n",
      "***************************************************************8\n",
      "\n",
      "Token Embeddings for Sentence:\n",
      " 1 tensor([[-1.3173, -0.4889, -2.0296,  ..., -1.2706, -0.0596,  0.0905],\n",
      "        [ 0.1539, -0.1608,  0.7088,  ..., -0.0658,  0.5019, -2.0494],\n",
      "        [ 1.1148,  0.3157, -0.9515,  ..., -0.1460,  0.2515, -0.2113],\n",
      "        ...,\n",
      "        [-0.8480,  0.4784, -1.2368,  ..., -0.9439, -0.0796,  1.1984],\n",
      "        [ 0.2358,  1.4300, -0.4178,  ..., -0.7669, -0.1203, -0.8616],\n",
      "        [ 1.4173,  1.0788,  0.5447,  ...,  0.0247,  0.4963,  0.2345]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Shape of the tensor:  torch.Size([86, 768])\n",
      "***************************************************************8\n",
      "\n",
      "Token Embeddings for Sentence:\n",
      " 2 tensor([[-1.3173, -0.4889, -2.0296,  ..., -1.2706, -0.0596,  0.0905],\n",
      "        [ 0.1539, -0.1608,  0.7088,  ..., -0.0658,  0.5019, -2.0494],\n",
      "        [ 1.1148,  0.3157, -0.9515,  ..., -0.1460,  0.2515, -0.2113],\n",
      "        ...,\n",
      "        [-0.7257,  0.5732, -1.0726,  ..., -0.3196, -1.0772,  0.2650],\n",
      "        [ 1.3769,  0.6835,  0.0475,  ...,  0.8544,  0.1968,  1.0711],\n",
      "        [ 1.4173,  1.0788,  0.5447,  ...,  0.0247,  0.4963,  0.2345]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Shape of the tensor:  torch.Size([86, 768])\n",
      "***************************************************************8\n",
      "Final Token Embeddings Shape: \n",
      " torch.Size([3, 86, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def generate_token_embeddings(token_ids, vocab_size, hidden_size):\n",
    "   \n",
    "    embedding_layer = nn.Embedding(vocab_size, hidden_size)\n",
    "\n",
    "    \n",
    "    token_tensor = torch.nn.utils.rnn.pad_sequence(\n",
    "        [torch.tensor(tokens) for tokens in token_ids],\n",
    "        batch_first=True\n",
    "    )\n",
    "\n",
    "\n",
    "    embeddings = embedding_layer(token_tensor)\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "vocab_size = 30522\n",
    "hidden_size = 768\n",
    "\n",
    "token_embeddings = generate_token_embeddings(TOKEN_IDS, vocab_size, hidden_size)\n",
    "\n",
    "print(\"Token Embeddings Shape:\", token_embeddings.shape)  \n",
    "\n",
    "for i in range(len(long_sentences)):\n",
    "    print(\"\\nToken Embeddings for Sentence:\\n\",i, token_embeddings[i])\n",
    "    print(\"Shape of the tensor: \",token_embeddings[i].shape)\n",
    "    print(\"***************************************************************8\")\n",
    "    \n",
    "print(\"Final Token Embeddings Shape: \\n\",token_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positional Embeddings: tensor([[-0.1937, -1.6509,  0.0524,  ..., -0.3078, -0.8161,  0.1402],\n",
      "        [-0.1640, -0.5365,  2.5154,  ...,  0.1293, -1.5503,  0.0813],\n",
      "        [ 0.2446, -1.1862,  0.5611,  ...,  1.9334,  0.3556, -0.2372],\n",
      "        ...,\n",
      "        [ 0.8061,  1.6361,  1.4724,  ...,  0.9765, -0.0786, -0.9160],\n",
      "        [-0.8116,  0.4125, -2.3977,  ..., -0.7698, -0.9078, -1.2793],\n",
      "        [-0.5043,  1.4386, -0.0188,  ...,  1.1596, -0.1285, -0.9348]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Shape:  torch.Size([86, 768])\n",
      "********************************************************************\n",
      "\n",
      "Positional Embeddings: tensor([[-0.1937, -1.6509,  0.0524,  ..., -0.3078, -0.8161,  0.1402],\n",
      "        [-0.1640, -0.5365,  2.5154,  ...,  0.1293, -1.5503,  0.0813],\n",
      "        [ 0.2446, -1.1862,  0.5611,  ...,  1.9334,  0.3556, -0.2372],\n",
      "        ...,\n",
      "        [ 0.8061,  1.6361,  1.4724,  ...,  0.9765, -0.0786, -0.9160],\n",
      "        [-0.8116,  0.4125, -2.3977,  ..., -0.7698, -0.9078, -1.2793],\n",
      "        [-0.5043,  1.4386, -0.0188,  ...,  1.1596, -0.1285, -0.9348]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Shape:  torch.Size([86, 768])\n",
      "********************************************************************\n",
      "\n",
      "Positional Embeddings: tensor([[-0.1937, -1.6509,  0.0524,  ..., -0.3078, -0.8161,  0.1402],\n",
      "        [-0.1640, -0.5365,  2.5154,  ...,  0.1293, -1.5503,  0.0813],\n",
      "        [ 0.2446, -1.1862,  0.5611,  ...,  1.9334,  0.3556, -0.2372],\n",
      "        ...,\n",
      "        [ 0.8061,  1.6361,  1.4724,  ...,  0.9765, -0.0786, -0.9160],\n",
      "        [-0.8116,  0.4125, -2.3977,  ..., -0.7698, -0.9078, -1.2793],\n",
      "        [-0.5043,  1.4386, -0.0188,  ...,  1.1596, -0.1285, -0.9348]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Shape:  torch.Size([86, 768])\n",
      "********************************************************************\n",
      "\n",
      "\n",
      "Final Positional Embeddings Shape:\n",
      " torch.Size([3, 86, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def generate_positional_embeddings(batch_size, max_length, hidden_size):\n",
    "    positional_embeddings = nn.Embedding(max_length, hidden_size)\n",
    "    positional_ids = torch.arange(max_length)\n",
    "    embeddings = positional_embeddings(positional_ids)\n",
    "    positional_embeddings_with_batch = embeddings.unsqueeze(0).expand(batch_size, -1, -1)\n",
    "    return positional_embeddings_with_batch\n",
    "\n",
    "batch_size = 3\n",
    "max_length = 86\n",
    "hidden_size = 768  \n",
    "\n",
    "positional_embeddings = generate_positional_embeddings(batch_size, max_length, hidden_size)\n",
    "for i in range(batch_size):\n",
    "    print(\"Positional Embeddings:\", positional_embeddings[i])\n",
    "    print(\"Shape: \",positional_embeddings[i].shape)\n",
    "    print(\"********************************************************************\\n\")\n",
    "print(\"\\nFinal Positional Embeddings Shape:\\n\", positional_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment Embedding:  tensor([[ 0.6256,  0.3246,  1.9778,  ...,  1.2585, -1.8255,  0.1230],\n",
      "        [ 0.6256,  0.3246,  1.9778,  ...,  1.2585, -1.8255,  0.1230],\n",
      "        [ 0.6256,  0.3246,  1.9778,  ...,  1.2585, -1.8255,  0.1230],\n",
      "        ...,\n",
      "        [-1.2266, -1.6429,  1.3023,  ..., -0.3819,  0.8702,  2.4243],\n",
      "        [-1.2266, -1.6429,  1.3023,  ..., -0.3819,  0.8702,  2.4243],\n",
      "        [-1.2266, -1.6429,  1.3023,  ..., -0.3819,  0.8702,  2.4243]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Shape:  torch.Size([86, 768])\n",
      "***************************************************************************\n",
      "Segment Embedding:  tensor([[ 0.6256,  0.3246,  1.9778,  ...,  1.2585, -1.8255,  0.1230],\n",
      "        [ 0.6256,  0.3246,  1.9778,  ...,  1.2585, -1.8255,  0.1230],\n",
      "        [ 0.6256,  0.3246,  1.9778,  ...,  1.2585, -1.8255,  0.1230],\n",
      "        ...,\n",
      "        [-1.2266, -1.6429,  1.3023,  ..., -0.3819,  0.8702,  2.4243],\n",
      "        [-1.2266, -1.6429,  1.3023,  ..., -0.3819,  0.8702,  2.4243],\n",
      "        [-1.2266, -1.6429,  1.3023,  ..., -0.3819,  0.8702,  2.4243]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Shape:  torch.Size([86, 768])\n",
      "***************************************************************************\n",
      "Segment Embedding:  tensor([[ 0.6256,  0.3246,  1.9778,  ...,  1.2585, -1.8255,  0.1230],\n",
      "        [ 0.6256,  0.3246,  1.9778,  ...,  1.2585, -1.8255,  0.1230],\n",
      "        [ 0.6256,  0.3246,  1.9778,  ...,  1.2585, -1.8255,  0.1230],\n",
      "        ...,\n",
      "        [-1.2266, -1.6429,  1.3023,  ..., -0.3819,  0.8702,  2.4243],\n",
      "        [-1.2266, -1.6429,  1.3023,  ..., -0.3819,  0.8702,  2.4243],\n",
      "        [-1.2266, -1.6429,  1.3023,  ..., -0.3819,  0.8702,  2.4243]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Shape:  torch.Size([86, 768])\n",
      "***************************************************************************\n",
      "\n",
      "Final Segment Embeddings:\n",
      " torch.Size([3, 86, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def generate_segment_embeddings(segment_ids, hidden_size):\n",
    "    # Create an embedding layer for two segments (0 and 1)\n",
    "    segment_embeddings = nn.Embedding(2, hidden_size)\n",
    "    \n",
    "    # Get the segment embeddings using the segment IDs\n",
    "    embeddings = segment_embeddings(segment_ids)\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "# Example parameters\n",
    "batch_size = 3\n",
    "max_length = 86\n",
    "hidden_size = 768  \n",
    "\n",
    "# Example segment IDs: a tensor of shape (batch_size, max_length)\n",
    "# Here, the first half is segment 0 and the second half is segment 1\n",
    "SEGMENT_IDS = torch.zeros((batch_size, max_length), dtype=torch.long)\n",
    "SEGMENT_IDS[:, max_length // 2:] = 1\n",
    "\n",
    "# Generate segment embeddings\n",
    "segment_embeddings = generate_segment_embeddings(SEGMENT_IDS, hidden_size)\n",
    "for i in range(batch_size):\n",
    "    print(\"Segment Embedding: \",segment_embeddings[i])\n",
    "    print(\"Shape: \",segment_embeddings[i].shape)\n",
    "    print(\"***************************************************************************\")\n",
    "# Output shape and embeddingsape:\", segment_embeddings.shape)  # Should be (batch_size, max_length, hidden_size)\n",
    "print(\"\\nFinal Segment Embeddings:\\n\", segment_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 86, 768])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_embeddings=token_embeddings+positional_embeddings\n",
    "combined_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.5110, -2.1397, -1.9772,  ..., -1.5784, -0.8757,  0.2308],\n",
       "         [-0.0100, -0.6972,  3.2242,  ...,  0.0634, -1.0484, -1.9681],\n",
       "         [ 1.3594, -0.8706, -0.3903,  ...,  1.7874,  0.6071, -0.4485],\n",
       "         ...,\n",
       "         [ 1.2416,  1.7125, -0.3357,  ...,  1.7380,  0.7953, -0.4523],\n",
       "         [-0.9303,  1.7891, -1.5026,  ..., -0.9074, -2.3523,  0.3905],\n",
       "         [ 0.9130,  2.5174,  0.5259,  ...,  1.1844,  0.3677, -0.7003]],\n",
       "\n",
       "        [[-1.5110, -2.1397, -1.9772,  ..., -1.5784, -0.8757,  0.2308],\n",
       "         [-0.0100, -0.6972,  3.2242,  ...,  0.0634, -1.0484, -1.9681],\n",
       "         [ 1.3594, -0.8706, -0.3903,  ...,  1.7874,  0.6071, -0.4485],\n",
       "         ...,\n",
       "         [-0.0419,  2.1145,  0.2356,  ...,  0.0326, -0.1581,  0.2824],\n",
       "         [-0.5758,  1.8425, -2.8155,  ..., -1.5366, -1.0282, -2.1409],\n",
       "         [ 0.9130,  2.5174,  0.5259,  ...,  1.1844,  0.3677, -0.7003]],\n",
       "\n",
       "        [[-1.5110, -2.1397, -1.9772,  ..., -1.5784, -0.8757,  0.2308],\n",
       "         [-0.0100, -0.6972,  3.2242,  ...,  0.0634, -1.0484, -1.9681],\n",
       "         [ 1.3594, -0.8706, -0.3903,  ...,  1.7874,  0.6071, -0.4485],\n",
       "         ...,\n",
       "         [ 0.0804,  2.2094,  0.3998,  ...,  0.6569, -1.1557, -0.6509],\n",
       "         [ 0.5653,  1.0960, -2.3502,  ...,  0.0847, -0.7110, -0.2082],\n",
       "         [ 0.9130,  2.5174,  0.5259,  ...,  1.1844,  0.3677, -0.7003]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Mask Shape: torch.Size([3, 86])\n",
      "Attention Mask:\n",
      " tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def generate_attention_mask(combined_embeddings):\n",
    "    batch_size, max_length, _ = combined_embeddings.shape\n",
    "    \n",
    "    attention_mask = (combined_embeddings != 0).any(dim=-1).long()\n",
    "    \n",
    "    return attention_mask\n",
    "\n",
    "batch_size = 3\n",
    "max_length = 86\n",
    "hidden_size = 768\n",
    "\n",
    "\n",
    "combined_embeddings = torch.rand((batch_size, max_length, hidden_size))  \n",
    "\n",
    "attention_mask = generate_attention_mask(combined_embeddings)\n",
    "\n",
    "\n",
    "print(\"Attention Mask Shape:\", attention_mask.shape)  \n",
    "print(\"Attention Mask:\\n\", attention_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Queries Matrix:-  tensor([[[ 3.7528e-01,  3.3901e-01,  1.6776e-01,  ..., -2.0755e-01,\n",
      "           1.9805e-01, -3.8161e-01],\n",
      "         [ 6.5055e-01,  3.7887e-01,  2.8131e-01,  ..., -2.2844e-01,\n",
      "          -4.9036e-02, -3.6855e-01],\n",
      "         [ 4.4325e-01,  9.6339e-02,  3.6114e-01,  ...,  6.7594e-02,\n",
      "          -1.3883e-01, -5.4448e-01],\n",
      "         ...,\n",
      "         [ 6.7491e-01,  3.2428e-01,  1.1466e-01,  ..., -1.5083e-02,\n",
      "           1.0284e-01,  7.9355e-03],\n",
      "         [ 5.2081e-01,  3.7057e-01,  1.5774e-01,  ...,  1.7238e-02,\n",
      "           3.2366e-03, -4.1652e-01],\n",
      "         [ 5.4127e-01,  2.7732e-01, -1.5818e-01,  ..., -1.1622e-01,\n",
      "           2.4825e-01, -4.5236e-01]],\n",
      "\n",
      "        [[ 4.5222e-01,  3.1255e-02,  4.1047e-01,  ..., -2.5653e-02,\n",
      "          -1.2489e-01, -3.6059e-01],\n",
      "         [ 6.5078e-01,  4.9359e-01,  2.7908e-01,  ..., -3.0817e-01,\n",
      "           2.0650e-01, -2.9903e-01],\n",
      "         [ 9.2715e-01,  2.3311e-01, -1.8400e-02,  ...,  1.2806e-01,\n",
      "          -2.7711e-02, -3.5027e-01],\n",
      "         ...,\n",
      "         [ 4.2015e-01,  3.6219e-01,  1.8274e-01,  ..., -9.4082e-02,\n",
      "          -1.1189e-01, -4.2609e-01],\n",
      "         [ 5.9961e-01,  4.3138e-01, -1.3166e-01,  ..., -2.3695e-01,\n",
      "          -1.9798e-01, -6.6628e-01],\n",
      "         [ 6.2500e-01,  2.6096e-01,  1.2513e-01,  ...,  2.6941e-03,\n",
      "          -2.3405e-01, -4.9502e-01]],\n",
      "\n",
      "        [[ 7.0855e-01,  4.4158e-01,  1.6951e-01,  ..., -7.5002e-02,\n",
      "          -4.0997e-02, -1.8591e-01],\n",
      "         [ 4.8989e-01,  2.5875e-01,  3.2110e-02,  ...,  5.7533e-02,\n",
      "          -2.4839e-01, -7.2760e-01],\n",
      "         [ 7.1613e-01,  1.0712e-01,  9.8829e-02,  ..., -1.1107e-01,\n",
      "          -3.1361e-01, -5.1144e-01],\n",
      "         ...,\n",
      "         [ 6.4627e-01,  2.9576e-01,  2.9257e-01,  ..., -1.8887e-01,\n",
      "          -5.9509e-02, -5.3301e-01],\n",
      "         [ 6.2476e-01,  4.0461e-01, -1.4621e-01,  ..., -3.4404e-01,\n",
      "           2.9070e-01, -2.8206e-01],\n",
      "         [ 9.0263e-01,  5.5882e-01,  3.2490e-01,  ..., -2.8665e-01,\n",
      "           6.9904e-04, -3.2796e-01]]], grad_fn=<ViewBackward0>)\n",
      "Queries Matrix Shape: torch.Size([3, 86, 768])\n",
      "\n",
      "Keys Matrix:-  tensor([[[-0.2296, -0.0503,  0.6742,  ...,  0.1879, -0.1879, -0.2238],\n",
      "         [-0.1088,  0.1513,  0.4851,  ..., -0.2332, -0.1987, -0.0440],\n",
      "         [ 0.1682, -0.0984,  0.4623,  ...,  0.0991, -0.2227,  0.0247],\n",
      "         ...,\n",
      "         [ 0.0227, -0.2321,  0.6840,  ...,  0.0551,  0.0391, -0.0978],\n",
      "         [ 0.2705, -0.0017,  0.4381,  ..., -0.3192, -0.3011, -0.1915],\n",
      "         [-0.0719, -0.1562,  0.4125,  ...,  0.3913, -0.0416, -0.3928]],\n",
      "\n",
      "        [[ 0.0285,  0.0612,  0.4548,  ..., -0.0070,  0.0876, -0.1894],\n",
      "         [ 0.0501,  0.0292,  0.5881,  ..., -0.1173, -0.2129, -0.0621],\n",
      "         [ 0.1179, -0.2068,  0.2327,  ...,  0.1014, -0.1839, -0.2807],\n",
      "         ...,\n",
      "         [ 0.2299, -0.0607,  0.6303,  ...,  0.1707, -0.0189, -0.1223],\n",
      "         [-0.1412, -0.2583,  0.1728,  ...,  0.1065, -0.1337, -0.0741],\n",
      "         [ 0.0855, -0.3271,  0.4035,  ...,  0.1397, -0.0479,  0.0573]],\n",
      "\n",
      "        [[-0.1378, -0.2650,  0.2845,  ..., -0.0087, -0.1784, -0.0213],\n",
      "         [-0.0492,  0.0807,  0.2585,  ...,  0.1290, -0.5251,  0.1985],\n",
      "         [-0.1757, -0.4583,  0.4510,  ...,  0.3259,  0.0192,  0.0955],\n",
      "         ...,\n",
      "         [-0.1593, -0.2680,  0.4201,  ..., -0.0635, -0.3879, -0.2406],\n",
      "         [ 0.0663,  0.1159,  0.5466,  ...,  0.2057, -0.1391,  0.0995],\n",
      "         [-0.2590,  0.2069,  0.4662,  ...,  0.1701,  0.0799,  0.0226]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "Keys Matrix Shape: torch.Size([3, 86, 768])\n",
      "\n",
      "Values Matrix:-  tensor([[[ 1.4287e-02,  3.5945e-01,  6.9636e-02,  ...,  5.1860e-01,\n",
      "           2.3332e-02, -7.5821e-01],\n",
      "         [-4.0272e-02,  3.2301e-01,  2.0892e-01,  ...,  1.5233e-01,\n",
      "           3.1985e-02, -9.1753e-01],\n",
      "         [ 1.7297e-01,  3.3559e-01, -2.1215e-01,  ...,  2.7048e-01,\n",
      "          -1.3385e-01, -1.1151e+00],\n",
      "         ...,\n",
      "         [ 3.5686e-02, -2.2519e-01, -2.3999e-01,  ...,  4.4389e-01,\n",
      "           3.1281e-01, -6.6354e-01],\n",
      "         [-2.4854e-01,  2.5407e-03, -1.3831e-01,  ...,  5.1540e-01,\n",
      "           2.5869e-01, -1.0842e+00],\n",
      "         [ 8.4315e-02, -1.0034e-01,  2.1775e-01,  ...,  1.9311e-01,\n",
      "           2.2404e-01, -1.0281e+00]],\n",
      "\n",
      "        [[ 3.1792e-01, -1.2757e-02,  1.6535e-01,  ...,  7.0654e-01,\n",
      "           2.4496e-01, -6.3369e-01],\n",
      "         [ 2.6465e-02, -8.5308e-02, -3.0186e-01,  ...,  4.0214e-01,\n",
      "           3.2989e-01, -8.8922e-01],\n",
      "         [ 1.6725e-01,  6.7664e-02,  1.5503e-01,  ...,  4.4012e-01,\n",
      "           5.1849e-01, -6.8445e-01],\n",
      "         ...,\n",
      "         [ 5.3344e-02,  2.0071e-01, -1.2836e-01,  ..., -2.6581e-01,\n",
      "           3.5052e-02, -1.0421e+00],\n",
      "         [ 1.5175e-01,  2.6821e-01, -7.2575e-02,  ...,  3.2245e-01,\n",
      "           1.4769e-01, -8.1612e-01],\n",
      "         [ 1.2307e-01,  4.4630e-02, -1.0270e-01,  ...,  3.3846e-01,\n",
      "           2.1516e-01, -4.7226e-01]],\n",
      "\n",
      "        [[ 6.2774e-01,  3.1402e-01, -1.1721e-01,  ...,  5.6473e-01,\n",
      "           2.4619e-01, -8.1681e-01],\n",
      "         [-6.8272e-02, -2.0906e-03, -1.1044e-01,  ...,  2.8984e-01,\n",
      "          -6.1623e-02, -9.6081e-01],\n",
      "         [ 3.1778e-01,  5.9404e-02,  1.5080e-01,  ...,  4.5792e-01,\n",
      "          -5.1194e-04, -1.0863e+00],\n",
      "         ...,\n",
      "         [-1.1416e-01, -4.8889e-02, -2.1290e-01,  ...,  2.7373e-01,\n",
      "           1.9654e-01, -5.0723e-01],\n",
      "         [ 2.5853e-02,  1.4913e-01,  8.7209e-02,  ...,  4.4723e-01,\n",
      "           4.5214e-01, -5.5792e-01],\n",
      "         [ 3.3696e-01,  2.3417e-01, -3.7094e-01,  ...,  4.6729e-01,\n",
      "           3.5323e-01, -5.3684e-01]]], grad_fn=<ViewBackward0>)\n",
      "Values Matrix Shape: torch.Size([3, 86, 768])\n",
      "Attention scores shape:  torch.Size([3, 12, 86, 86])\n",
      "Attention score shape after softmax:  torch.Size([3, 12, 86, 86])\n",
      "Output Embeddings Shape: torch.Size([3, 86, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, hidden_size, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = hidden_size // num_heads\n",
    "\n",
    "        assert (\n",
    "            hidden_size % num_heads == 0\n",
    "        ), \"hidden_size must be divisible by num_heads\"\n",
    "\n",
    "        self.query_linear = nn.Linear(hidden_size, hidden_size)\n",
    "        self.key_linear = nn.Linear(hidden_size, hidden_size)\n",
    "        self.value_linear = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc_out = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_length, hidden_size = x.size()\n",
    "\n",
    "        queries = self.query_linear(x)  \n",
    "        keys = self.key_linear(x)\n",
    "        values = self.value_linear(x)\n",
    "\n",
    "        # Print the query, key, and value matrices\n",
    "        print(\"\\nQueries Matrix:- \",queries)\n",
    "        print(\"Queries Matrix Shape:\", queries.shape)\n",
    "        print(\"\\nKeys Matrix:- \",keys)\n",
    "        print(\"Keys Matrix Shape:\", keys.shape)\n",
    "        print(\"\\nValues Matrix:- \",values)\n",
    "        print(\"Values Matrix Shape:\", values.shape)\n",
    "\n",
    "        # Reshape for multi-head attention\n",
    "        queries = queries.view(batch_size, seq_length, self.num_heads, self.head_dim).transpose(1, 2)  # (batch_size, num_heads, seq_length, head_dim)\n",
    "        keys = keys.view(batch_size, seq_length, self.num_heads, self.head_dim).transpose(1, 2)  # (batch_size, num_heads, seq_length, head_dim)\n",
    "        values = values.view(batch_size, seq_length, self.num_heads, self.head_dim).transpose(1, 2)  # (batch_size, num_heads, seq_length, head_dim)\n",
    "        energy = torch.einsum(\"nhqd,nhkd->nhqk\", [queries, keys])  # (batch_size, num_heads, seq_length, seq_length)\n",
    "\n",
    "        attention_scores = energy / (self.head_dim ** 0.5)\n",
    "        print(\"Attention scores shape: \",attention_scores.shape)\n",
    "        attention = torch.softmax(energy / (self.head_dim ** 0.5), dim=3)  # Scale and softmax\n",
    "        print(\"Attention score shape after softmax: \",attention.shape)\n",
    "        out = torch.einsum(\"nhql,nhld->nhqd\", [attention, values]).reshape(batch_size, seq_length, hidden_size)  # (batch_size, seq_length, hidden_size)\n",
    "        out = self.fc_out(out)  # Final linear layer\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "batch_size = 3\n",
    "seq_length = 86\n",
    "hidden_size = 768\n",
    "num_heads = 12\n",
    "\n",
    "attention_layer = MultiHeadAttention(hidden_size, num_heads)\n",
    "\n",
    "\n",
    "combined_embeddings = combined_embeddings\n",
    "\n",
    "\n",
    "output_embeddings = attention_layer(combined_embeddings)\n",
    "\n",
    "print(\"Output Embeddings Shape:\", output_embeddings.shape)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1186, -0.2490, -0.1706,  ..., -0.0857, -0.0484, -0.2073],\n",
       "         [ 0.1186, -0.2490, -0.1711,  ..., -0.0852, -0.0487, -0.2075],\n",
       "         [ 0.1186, -0.2492, -0.1708,  ..., -0.0858, -0.0486, -0.2071],\n",
       "         ...,\n",
       "         [-0.0590,  0.0368, -0.1373,  ..., -0.0091, -0.0807,  0.0887],\n",
       "         [-0.0586,  0.0376, -0.1377,  ..., -0.0091, -0.0818,  0.0887],\n",
       "         [-0.0591,  0.0367, -0.1376,  ..., -0.0092, -0.0817,  0.0881]],\n",
       "\n",
       "        [[ 0.1228, -0.2434, -0.1613,  ..., -0.0692, -0.0629, -0.1992],\n",
       "         [ 0.1235, -0.2444, -0.1609,  ..., -0.0690, -0.0635, -0.1996],\n",
       "         [ 0.1230, -0.2449, -0.1609,  ..., -0.0698, -0.0632, -0.1996],\n",
       "         ...,\n",
       "         [-0.0963,  0.0454, -0.1496,  ..., -0.0212, -0.0903,  0.1068],\n",
       "         [-0.0957,  0.0450, -0.1501,  ..., -0.0208, -0.0903,  0.1067],\n",
       "         [-0.0958,  0.0452, -0.1489,  ..., -0.0212, -0.0904,  0.1063]],\n",
       "\n",
       "        [[ 0.1270, -0.2272, -0.1631,  ..., -0.0776, -0.0595, -0.2086],\n",
       "         [ 0.1272, -0.2273, -0.1627,  ..., -0.0777, -0.0597, -0.2084],\n",
       "         [ 0.1272, -0.2274, -0.1625,  ..., -0.0781, -0.0601, -0.2085],\n",
       "         ...,\n",
       "         [-0.1022,  0.0529, -0.1342,  ..., -0.0249, -0.0792,  0.0805],\n",
       "         [-0.1023,  0.0532, -0.1341,  ..., -0.0245, -0.0790,  0.0805],\n",
       "         [-0.1023,  0.0531, -0.1342,  ..., -0.0254, -0.0798,  0.0807]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QAHead(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(QAHead, self).__init__()\n",
    "        self.start_logits = nn.Linear(hidden_size, 1)\n",
    "        self.end_logits = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, embeddings):\n",
    "        start_logits = self.start_logits(embeddings).squeeze(-1)  \n",
    "        end_logits = self.end_logits(embeddings).squeeze(-1)      \n",
    "        return start_logits, end_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Logits Shape: torch.Size([3, 86])\n",
      "End Logits Shape: torch.Size([3, 86])\n"
     ]
    }
   ],
   "source": [
    "qa_head = QAHead(hidden_size)\n",
    "start_logits, end_logits = qa_head(output_embeddings)\n",
    "\n",
    "print(\"Start Logits Shape:\", start_logits.shape)  \n",
    "print(\"End Logits Shape:\", end_logits.shape)      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.1136, -0.1135, -0.1134, -0.1134, -0.1133, -0.1133, -0.1133,  0.0131,\n",
       "           0.0237,  0.0236,  0.0236,  0.0234,  0.0237,  0.0237, -0.0810, -0.0051,\n",
       "          -0.0051, -0.0050, -0.0054, -0.0051, -0.0054,  0.0667,  0.0439,  0.0437,\n",
       "           0.0439,  0.0440,  0.0442,  0.0440, -0.0736, -0.1884, -0.1882, -0.1884,\n",
       "          -0.1888, -0.1887, -0.1884, -0.0981, -0.1854, -0.1853, -0.1854, -0.1855,\n",
       "          -0.1857, -0.1856, -0.1854, -0.2822, -0.2826, -0.2825, -0.2825, -0.2826,\n",
       "          -0.2826, -0.2823, -0.2079, -0.2043, -0.2042, -0.2044, -0.2039, -0.2042,\n",
       "          -0.2043, -0.1205, -0.0337, -0.0336, -0.0337, -0.0338, -0.0338, -0.0334,\n",
       "           0.0836,  0.0182,  0.0183,  0.0182,  0.0185,  0.0184,  0.0184,  0.0386,\n",
       "          -0.0073, -0.0077, -0.0074, -0.0074, -0.0077, -0.0074, -0.0504, -0.1613,\n",
       "          -0.1612, -0.1613, -0.1613, -0.1612, -0.1612, -0.1612],\n",
       "         [-0.1192, -0.1189, -0.1191, -0.1191, -0.1190, -0.1191, -0.1191,  0.0302,\n",
       "           0.0378,  0.0376,  0.0379,  0.0381,  0.0379,  0.0382, -0.0739,  0.0011,\n",
       "           0.0008,  0.0012,  0.0008,  0.0011,  0.0012,  0.0652,  0.0399,  0.0399,\n",
       "           0.0397,  0.0398,  0.0395,  0.0398, -0.0704, -0.1769, -0.1768, -0.1769,\n",
       "          -0.1766, -0.1769, -0.1765, -0.0851, -0.1775, -0.1776, -0.1777, -0.1774,\n",
       "          -0.1776, -0.1776, -0.1775, -0.2624, -0.2626, -0.2625, -0.2625, -0.2628,\n",
       "          -0.2623, -0.2622, -0.1927, -0.1979, -0.1976, -0.1975, -0.1978, -0.1975,\n",
       "          -0.1975, -0.1159, -0.0366, -0.0365, -0.0364, -0.0365, -0.0365, -0.0365,\n",
       "           0.0839,  0.0257,  0.0255,  0.0254,  0.0255,  0.0256,  0.0256,  0.0382,\n",
       "          -0.0094, -0.0094, -0.0099, -0.0093, -0.0096, -0.0094, -0.0461, -0.1450,\n",
       "          -0.1451, -0.1453, -0.1453, -0.1453, -0.1453, -0.1451],\n",
       "         [-0.1210, -0.1216, -0.1216, -0.1213, -0.1214, -0.1214, -0.1215,  0.0218,\n",
       "           0.0367,  0.0366,  0.0366,  0.0366,  0.0364,  0.0367, -0.0748, -0.0028,\n",
       "          -0.0028, -0.0027, -0.0027, -0.0028, -0.0029,  0.0669,  0.0481,  0.0483,\n",
       "           0.0483,  0.0480,  0.0482,  0.0483, -0.0677, -0.1775, -0.1774, -0.1776,\n",
       "          -0.1775, -0.1777, -0.1775, -0.0865, -0.1911, -0.1908, -0.1911, -0.1909,\n",
       "          -0.1908, -0.1909, -0.1911, -0.2770, -0.2767, -0.2770, -0.2770, -0.2767,\n",
       "          -0.2770, -0.2768, -0.2142, -0.2118, -0.2120, -0.2119, -0.2115, -0.2117,\n",
       "          -0.2120, -0.1214, -0.0340, -0.0338, -0.0341, -0.0342, -0.0341, -0.0339,\n",
       "           0.0963,  0.0365,  0.0362,  0.0364,  0.0366,  0.0363,  0.0365,  0.0449,\n",
       "          -0.0063, -0.0063, -0.0064, -0.0064, -0.0065, -0.0062, -0.0455, -0.1532,\n",
       "          -0.1529, -0.1531, -0.1530, -0.1527, -0.1532, -0.1528]],\n",
       "        grad_fn=<SqueezeBackward1>),\n",
       " tensor([[ 0.1023,  0.1023,  0.1025,  0.1023,  0.1024,  0.1021,  0.1024,  0.0638,\n",
       "          -0.0177, -0.0178, -0.0179, -0.0179, -0.0177, -0.0179, -0.0478, -0.1377,\n",
       "          -0.1377, -0.1374, -0.1376, -0.1377, -0.1374, -0.1448,  0.0455,  0.0453,\n",
       "           0.0456,  0.0459,  0.0456,  0.0458,  0.1152, -0.0928, -0.0926, -0.0931,\n",
       "          -0.0927, -0.0931, -0.0930, -0.1208, -0.0831, -0.0830, -0.0830, -0.0828,\n",
       "          -0.0826, -0.0830, -0.0828,  0.0322,  0.0327,  0.0325,  0.0324,  0.0321,\n",
       "           0.0325,  0.0324,  0.1060,  0.0678,  0.0678,  0.0680,  0.0678,  0.0677,\n",
       "           0.0680, -0.1218, -0.1504, -0.1502, -0.1504, -0.1501, -0.1503, -0.1505,\n",
       "          -0.0835, -0.1296, -0.1298, -0.1297, -0.1294, -0.1293, -0.1298, -0.1457,\n",
       "           0.0510,  0.0515,  0.0512,  0.0515,  0.0510,  0.0511,  0.0105, -0.0637,\n",
       "          -0.0640, -0.0640, -0.0640, -0.0641, -0.0640, -0.0639],\n",
       "         [ 0.0877,  0.0881,  0.0880,  0.0878,  0.0882,  0.0882,  0.0877,  0.0723,\n",
       "          -0.0061, -0.0062, -0.0063, -0.0064, -0.0062, -0.0062, -0.0473, -0.1384,\n",
       "          -0.1387, -0.1386, -0.1386, -0.1387, -0.1382, -0.1453,  0.0500,  0.0500,\n",
       "           0.0500,  0.0501,  0.0499,  0.0502,  0.1230, -0.0883, -0.0882, -0.0883,\n",
       "          -0.0880, -0.0886, -0.0881, -0.1178, -0.0731, -0.0732, -0.0730, -0.0730,\n",
       "          -0.0731, -0.0730, -0.0730,  0.0276,  0.0276,  0.0276,  0.0275,  0.0278,\n",
       "           0.0277,  0.0279,  0.1100,  0.0758,  0.0752,  0.0756,  0.0754,  0.0754,\n",
       "           0.0755, -0.1202, -0.1592, -0.1591, -0.1591, -0.1591, -0.1590, -0.1592,\n",
       "          -0.0915, -0.1363, -0.1360, -0.1364, -0.1360, -0.1360, -0.1360, -0.1451,\n",
       "           0.0542,  0.0542,  0.0541,  0.0543,  0.0542,  0.0544,  0.0090, -0.0710,\n",
       "          -0.0708, -0.0707, -0.0706, -0.0708, -0.0709, -0.0709],\n",
       "         [ 0.0955,  0.0954,  0.0952,  0.0954,  0.0953,  0.0949,  0.0953,  0.0772,\n",
       "          -0.0015, -0.0019, -0.0021, -0.0017, -0.0016, -0.0017, -0.0421, -0.1392,\n",
       "          -0.1396, -0.1395, -0.1396, -0.1395, -0.1396, -0.1362,  0.0566,  0.0567,\n",
       "           0.0569,  0.0564,  0.0566,  0.0565,  0.1337, -0.0880, -0.0876, -0.0879,\n",
       "          -0.0876, -0.0880, -0.0874, -0.1116, -0.0725, -0.0724, -0.0726, -0.0726,\n",
       "          -0.0727, -0.0725, -0.0724,  0.0318,  0.0320,  0.0320,  0.0323,  0.0322,\n",
       "           0.0321,  0.0322,  0.1070,  0.0737,  0.0739,  0.0738,  0.0738,  0.0740,\n",
       "           0.0738, -0.1092, -0.1500, -0.1500, -0.1496, -0.1498, -0.1499, -0.1498,\n",
       "          -0.0916, -0.1330, -0.1330, -0.1330, -0.1332, -0.1328, -0.1326, -0.1501,\n",
       "           0.0597,  0.0595,  0.0595,  0.0594,  0.0595,  0.0594,  0.0169, -0.0603,\n",
       "          -0.0602, -0.0599, -0.0602, -0.0606, -0.0604, -0.0601]],\n",
       "        grad_fn=<SqueezeBackward1>))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_logits,end_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([64, 64, 64]), tensor([28, 28, 28]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_positions = torch.argmax(start_logits, dim=-1)\n",
    "end_positions = torch.argmax(end_logits, dim=-1)\n",
    "start_positions,end_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1:\n",
      "What is Cybersecurity?\n",
      "\n",
      "Question 1:\n",
      "What is Malware?\n",
      "\n",
      "Question 1:\n",
      "What is Phishing?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx=0\n",
    "for l in long_sentences:\n",
    "    print(\"Question 1:\")\n",
    "    print(l[0])\n",
    "    print(l[1][start_positions[idx]:end_positions[idx]])\n",
    "    idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
