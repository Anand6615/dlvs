{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T08:48:50.536596Z",
     "iopub.status.busy": "2024-11-14T08:48:50.536218Z",
     "iopub.status.idle": "2024-11-14T08:48:50.540925Z",
     "shell.execute_reply": "2024-11-14T08:48:50.539901Z",
     "shell.execute_reply.started": "2024-11-14T08:48:50.536560Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### BERT MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The bert-base model has a vocabulary size of 30522 (vocab_size) → vocab_size. \n",
    "### The maximum length of the input sequences 512 tokens → model_max_length.\n",
    "### Determines which side of the sequence to truncate when it exceeds the model_max_length. Right truncation means that ### tokens will be removed from the end of the sequence, left means tokens will be removed from start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### token id's generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T09:43:30.675672Z",
     "iopub.status.busy": "2024-11-14T09:43:30.675324Z",
     "iopub.status.idle": "2024-11-14T09:43:30.837308Z",
     "shell.execute_reply": "2024-11-14T09:43:30.836356Z",
     "shell.execute_reply.started": "2024-11-14T09:43:30.675640Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is Cybersecurity?...\n",
      "Tokens: ['[CLS]', 'what', 'is', 'cyber', '##se', '##cu', '##rity', '?', '[SEP]', 'cyber', '##se', '##cu', '##rity', 'is', 'the', 'practice', 'of', 'protecting', 'systems', ',', 'networks', ',', 'and', 'programs', 'from', 'digital', 'attacks', ',', 'theft', ',', 'or', 'damage', '.', 'these', 'cyber', '##att', '##ack', '##s', 'usually', 'aim', 'to', 'access', ',', 'alter', ',', 'or', 'destroy', 'sensitive', 'information', ',', 'ex', '##tort', 'money', ',', 'or', 'disrupt', 'normal', 'business', 'operations', '.', 'key', 'components', 'include', ':', '-', 'network', 'security', ':', 'protecting', 'network', 'integrity', 'and', 'data', '.', '-', 'application', 'security', ':', 'securing', 'applications', 'by', 'identifying', 'vu', '##ln', '##era', '[SEP]']...\n",
      "Token IDs: [101, 2054, 2003, 16941, 3366, 10841, 15780, 1029, 102, 16941, 3366, 10841, 15780, 2003, 1996, 3218, 1997, 8650, 3001, 1010, 6125, 1010, 1998, 3454, 2013, 3617, 4491, 1010, 11933, 1010, 2030, 4053, 1012, 2122, 16941, 19321, 8684, 2015, 2788, 6614, 2000, 3229, 1010, 11477, 1010, 2030, 6033, 7591, 2592, 1010, 4654, 25485, 2769, 1010, 2030, 23217, 3671, 2449, 3136, 1012, 3145, 6177, 2421, 1024, 1011, 2897, 3036, 1024, 8650, 2897, 11109, 1998, 2951, 1012, 1011, 4646, 3036, 1024, 12329, 5097, 2011, 12151, 24728, 19666, 6906, 102]...\n",
      "\n",
      "\n",
      "Token shape for sentence is (1, 86)\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "\n",
      "Question: What is Malware?...\n",
      "Tokens: ['[CLS]', 'what', 'is', 'mal', '##ware', '?', '[SEP]', 'mal', '##ware', ',', 'short', 'for', 'malicious', 'software', ',', 'refers', 'to', 'any', 'software', 'designed', 'to', 'cause', 'harm', 'to', 'a', 'computer', ',', 'network', ',', 'or', 'server', '.', 'it', 'is', 'used', 'by', 'attackers', 'to', 'steal', 'data', ',', 'spy', 'on', 'users', ',', 'or', 'damage', 'systems', '.', 'types', 'of', 'mal', '##ware', 'include', ':', '-', 'viruses', ':', 'in', '##fect', 'programs', 'and', 'replicate', '.', '-', 'worms', ':', 'spread', 'independently', 'across', 'networks', '.', '-', 'trojan', 'horses', ':', 'disguised', 'as', 'legitimate', 'software', 'but', 'deliver', 'malicious', 'payload', '##s', '[SEP]']...\n",
      "Token IDs: [101, 2054, 2003, 15451, 8059, 1029, 102, 15451, 8059, 1010, 2460, 2005, 24391, 4007, 1010, 5218, 2000, 2151, 4007, 2881, 2000, 3426, 7386, 2000, 1037, 3274, 1010, 2897, 1010, 2030, 8241, 1012, 2009, 2003, 2109, 2011, 17857, 2000, 8954, 2951, 1010, 8645, 2006, 5198, 1010, 2030, 4053, 3001, 1012, 4127, 1997, 15451, 8059, 2421, 1024, 1011, 18191, 1024, 1999, 25969, 3454, 1998, 28024, 1012, 1011, 16253, 1024, 3659, 9174, 2408, 6125, 1012, 1011, 23445, 5194, 1024, 17330, 2004, 11476, 4007, 2021, 8116, 24391, 18093, 2015, 102]...\n",
      "\n",
      "\n",
      "Token shape for sentence is (1, 86)\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "\n",
      "Question: What is Phishing?...\n",
      "Tokens: ['[CLS]', 'what', 'is', 'phi', '##shing', '?', '[SEP]', 'phi', '##shing', 'is', 'a', 'type', 'of', 'cyber', '##att', '##ack', 'where', 'attackers', 'imp', '##erson', '##ate', 'legitimate', 'entities', 'to', 'trick', 'individuals', 'into', 'revealing', 'sensitive', 'information', 'such', 'as', 'user', '##name', '##s', ',', 'password', '##s', ',', 'or', 'financial', 'details', '.', 'phi', '##shing', 'typically', 'occurs', 'through', 'dec', '##eptive', 'emails', ',', 'websites', ',', 'or', 'messages', 'that', 'appear', 'to', 'come', 'from', 'trusted', 'sources', '.', 'common', 'types', 'of', 'phi', '##shing', 'attacks', 'include', ':', '-', 'spear', 'phi', '##shing', ':', 'targeted', 'attacks', 'aimed', 'at', 'specific', 'individuals', 'or', 'organizations', '[SEP]']...\n",
      "Token IDs: [101, 2054, 2003, 13569, 12227, 1029, 102, 13569, 12227, 2003, 1037, 2828, 1997, 16941, 19321, 8684, 2073, 17857, 17727, 18617, 3686, 11476, 11422, 2000, 7577, 3633, 2046, 8669, 7591, 2592, 2107, 2004, 5310, 18442, 2015, 1010, 20786, 2015, 1010, 2030, 3361, 4751, 1012, 13569, 12227, 4050, 5158, 2083, 11703, 22048, 22028, 1010, 11744, 1010, 2030, 7696, 2008, 3711, 2000, 2272, 2013, 9480, 4216, 1012, 2691, 4127, 1997, 13569, 12227, 4491, 2421, 1024, 1011, 12341, 13569, 12227, 1024, 9416, 4491, 6461, 2012, 3563, 3633, 2030, 4411, 102]...\n",
      "\n",
      "\n",
      "Token shape for sentence is (1, 86)\n",
      "\n",
      "\n",
      "*********************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "long_sentences = [\n",
    "    [\n",
    "        \"What is Cybersecurity?\",\n",
    "        \"Cybersecurity is the practice of protecting systems, networks, and programs from digital attacks, theft, or damage. These cyberattacks usually aim to access, alter, or destroy sensitive information, extort money, or disrupt normal business operations. Key components include:\\n\"\n",
    "        \"- Network Security: Protecting network integrity and data.\\n\"\n",
    "        \"- Application Security: Securing applications by identifying vulnerabilities.\\n\"\n",
    "        \"- Information Security: Ensuring data privacy and integrity.\\n\"\n",
    "        \"- Operational Security: Managing data handling and protection practices.\\n\"\n",
    "        \"Methods such as firewalls, encryption, antivirus software, and multi-factor authentication (MFA) are employed to mitigate cyber threats.\"\n",
    "    ],\n",
    "    [\n",
    "        \"What is Malware?\",\n",
    "        \"Malware, short for malicious software, refers to any software designed to cause harm to a computer, network, or server. It is used by attackers to steal data, spy on users, or damage systems. Types of malware include:\\n\"\n",
    "        \"- Viruses: Infect programs and replicate.\\n\"\n",
    "        \"- Worms: Spread independently across networks.\\n\"\n",
    "        \"- Trojan Horses: Disguised as legitimate software but deliver malicious payloads.\\n\"\n",
    "        \"- Ransomware: Encrypts data and demands payment for decryption.\\n\"\n",
    "        \"- Spyware: Collects and transmits user data secretly.\\n\"\n",
    "        \"- Adware: Shows unwanted ads and may track user data.\\n\"\n",
    "        \"Entry points include infected websites, email attachments, and social engineering.\"\n",
    "    ],\n",
    "    [\n",
    "    \"What is Phishing?\",\n",
    "    \"Phishing is a type of cyberattack where attackers impersonate legitimate entities to trick individuals into revealing sensitive information such as usernames, passwords, or financial details. Phishing typically occurs through deceptive emails, websites, or messages that appear to come from trusted sources.\\n\"\n",
    "    \"Common types of phishing attacks include:\\n\"\n",
    "    \"- Spear Phishing: Targeted attacks aimed at specific individuals or organizations.\\n\"\n",
    "    \"- Whaling: Phishing attempts directed at high-profile targets like executives or senior management.\\n\"\n",
    "    \"- Smishing: Phishing conducted through SMS text messages.\\n\"\n",
    "    \"- Vishing: Voice-based phishing scams.\\n\"\n",
    "    \"Phishing is often identified by suspicious links, urgent requests for personal information, and poor grammar in communications. Users can protect themselves by scrutinizing sender details, avoiding clicking on unverified links, and enabling multi-factor authentication.\"\n",
    "]\n",
    "]\n",
    "ma=86\n",
    "l=sorted(long_sentences,key=len,reverse=True)\n",
    "max_length=ma\n",
    "TOKEN_IDS=[]\n",
    "i=0\n",
    "SEGMENT_IDS=[]\n",
    "for sentence in long_sentences:\n",
    "    encoded_input = tokenizer(\n",
    "        sentence[0],sentence[1],\n",
    "        max_length=max_length,      \n",
    "        truncation=True,     \n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    tokens = tokenizer.convert_ids_to_tokens(encoded_input[\"input_ids\"])\n",
    "    \n",
    "    print(f\"Question: {sentence[0][:]}...\")  \n",
    "#     print(f\"Answer:{sentence[1]:[:]}...\")\n",
    "    print(f\"Tokens: {tokens}...\")       \n",
    "    print(f\"Token IDs: {encoded_input['input_ids']}...\")\n",
    "    print(\"\\n\")\n",
    "#     print(\"Length of the sentence is\",len(sentence[0].split(\" \")))\n",
    "    print(\"Token shape for sentence is\",np.array([tokens]).shape)\n",
    "#     print(\"Length of Encoded Input of this sentence is\",len(encoded_input['input_ids'][:50]))\n",
    "    print(\"\\n\")\n",
    "    print(\"*********************************************************\\n\")\n",
    "    TOKEN_IDS.append(np.array(encoded_input['input_ids']))\n",
    "    SEGMENT_IDS.append(np.array([i for j in range(36)]))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment Id's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T09:39:48.775982Z",
     "iopub.status.busy": "2024-11-14T09:39:48.775572Z",
     "iopub.status.idle": "2024-11-14T09:39:48.781049Z",
     "shell.execute_reply": "2024-11-14T09:39:48.780032Z",
     "shell.execute_reply.started": "2024-11-14T09:39:48.775942Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from transformers import BertTokenizer\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# sentences=long_sentences\n",
    "\n",
    "# max_length = 36 \n",
    "\n",
    "# encoded_pair_1 = tokenizer(\n",
    "#     sentences[0], sentences[1],\n",
    "#     max_length=max_length,\n",
    "#     padding=\"max_length\",\n",
    "#     truncation=True,\n",
    "#     return_tensors=\"pt\"\n",
    "# )\n",
    "\n",
    "# encoded_pair_2 = tokenizer(\n",
    "#     sentences[1], sentences[2],\n",
    "#     max_length=max_length,\n",
    "#     padding=\"max_length\",\n",
    "#     truncation=True,\n",
    "#     return_tensors=\"pt\"\n",
    "# )\n",
    "\n",
    "\n",
    "# print(\"Pair 1 - Input IDs:\", encoded_pair_1[\"input_ids\"])\n",
    "# print(\"Tensor shape: \",encoded_pair_1['input_ids'].shape)\n",
    "# print(\"Pair 1 - Segment IDs:\", encoded_pair_1[\"token_type_ids\"])\n",
    "\n",
    "# print(\"\\nPair 2 - Input IDs:\", encoded_pair_2[\"input_ids\"])\n",
    "# print(\"Tensor shape: \",encoded_pair_2['input_ids'].shape)\n",
    "# print(\"Pair 2 - Segment IDs:\", encoded_pair_2[\"token_type_ids\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postional Id's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T09:43:39.202920Z",
     "iopub.status.busy": "2024-11-14T09:43:39.202242Z",
     "iopub.status.idle": "2024-11-14T09:43:39.214723Z",
     "shell.execute_reply": "2024-11-14T09:43:39.213733Z",
     "shell.execute_reply.started": "2024-11-14T09:43:39.202870Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Complete Positional IDs:\n",
      " tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "         54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "         72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85],\n",
      "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "         54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "         72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85],\n",
      "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "         54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "         72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85]])\n",
      "Shapes are: \n",
      "********************************************\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85])\n",
      "(1, 86)\n",
      "********************************************\n",
      "********************************************\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85])\n",
      "(1, 86)\n",
      "********************************************\n",
      "********************************************\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85])\n",
      "(1, 86)\n",
      "********************************************\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def generate_positional_ids(sentences, max_length):\n",
    "    \n",
    "    positional_ids = torch.arange(max_length).unsqueeze(0).expand(len(sentences), -1)\n",
    "    \n",
    "    return positional_ids\n",
    "\n",
    "# Example usage\n",
    "max_length=86\n",
    "  # Specify the maximum length\n",
    "positional_ids = generate_positional_ids(long_sentences, max_length)\n",
    "\n",
    "print(\" Complete Positional IDs:\\n\", positional_ids)\n",
    "print(\"Shapes are: \")\n",
    "POSITIONAL_IDS=[]\n",
    "for tensors in positional_ids:\n",
    "    print(\"********************************************\")\n",
    "    print(tensors)\n",
    "    print(np.array([tensors]).shape)\n",
    "    print(\"********************************************\")\n",
    "    POSITIONAL_IDS.append(np.array(tensors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T09:43:46.217061Z",
     "iopub.status.busy": "2024-11-14T09:43:46.216307Z",
     "iopub.status.idle": "2024-11-14T09:43:46.221325Z",
     "shell.execute_reply": "2024-11-14T09:43:46.220270Z",
     "shell.execute_reply.started": "2024-11-14T09:43:46.217022Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "TOKEN_IDS=np.array(TOKEN_IDS)\n",
    "POSITIONAL_IDS=np.array(POSITIONAL_IDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T09:43:49.497025Z",
     "iopub.status.busy": "2024-11-14T09:43:49.496625Z",
     "iopub.status.idle": "2024-11-14T09:43:49.502174Z",
     "shell.execute_reply": "2024-11-14T09:43:49.501147Z",
     "shell.execute_reply.started": "2024-11-14T09:43:49.496987Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 86)\n",
      "(3, 86)\n"
     ]
    }
   ],
   "source": [
    "print(TOKEN_IDS.shape)\n",
    "# print(SEGMENT_IDS.shape)\n",
    "print(POSITIONAL_IDS.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T09:43:58.990942Z",
     "iopub.status.busy": "2024-11-14T09:43:58.990309Z",
     "iopub.status.idle": "2024-11-14T09:43:58.995869Z",
     "shell.execute_reply": "2024-11-14T09:43:58.994908Z",
     "shell.execute_reply.started": "2024-11-14T09:43:58.990900Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 86)\n"
     ]
    }
   ],
   "source": [
    "combined_ids=TOKEN_IDS+POSITIONAL_IDS\n",
    "print(combined_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T09:44:06.706792Z",
     "iopub.status.busy": "2024-11-14T09:44:06.706420Z",
     "iopub.status.idle": "2024-11-14T09:44:06.714040Z",
     "shell.execute_reply": "2024-11-14T09:44:06.712998Z",
     "shell.execute_reply.started": "2024-11-14T09:44:06.706756Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  101,  2055,  2005, 16944,  3370, 10846, 15786,  1036,   110,\n",
       "        16950,  3376, 10852, 15792,  2016,  2010,  3233,  2013,  8667,\n",
       "         3019,  1029,  6145,  1031,  2020,  3477,  2037,  3642,  4517,\n",
       "         1037, 11961,  1039,  2060,  4084,  1044,  2155, 16975, 19356,\n",
       "         8720,  2052,  2826,  6653,  2040,  3270,  1052, 11520,  1054,\n",
       "         2075,  6079,  7638,  2640,  1059,  4704, 25536,  2821,  1063,\n",
       "         2084, 23272,  3727,  2506,  3194,  1071,  3205,  6238,  2483,\n",
       "         1087,  1075,  2962,  3102,  1091,  8718,  2966, 11179,  2069,\n",
       "         3023,  1085,  1085,  4721,  3112,  1101, 12407,  5176,  2091,\n",
       "        12232, 24810, 19749,  6990,   187],\n",
       "       [  101,  2055,  2005, 15454,  8063,  1034,   108, 15458,  8067,\n",
       "         1019,  2470,  2016, 24403,  4020,  1024,  5233,  2016,  2168,\n",
       "         4025,  2900,  2020,  3447,  7408,  2023,  1061,  3299,  1036,\n",
       "         2924,  1038,  2059,  8271,  1043,  2041,  2036,  2143,  2046,\n",
       "        17893,  2037,  8992,  2990,  1050,  8686,  2048,  5241,  1054,\n",
       "         2075,  4099,  3048,  1060,  4176,  2047, 15502,  8111,  2474,\n",
       "         1078,  1066, 18247,  1081,  2057, 26028,  3514,  2059, 28086,\n",
       "         1075,  1075, 16318,  1090,  3726,  9242,  2477,  6195,  1083,\n",
       "         1083, 23518,  5268,  1099, 17406,  2081, 11554,  4086,  2101,\n",
       "         8197, 24473, 18176,  2099,   187],\n",
       "       [  101,  2055,  2005, 13572, 12231,  1034,   108, 13576, 12235,\n",
       "         2012,  1047,  2839,  2009, 16954, 19335,  8699,  2089, 17874,\n",
       "        17745, 18636,  3706, 11497, 11444,  2023,  7601,  3658,  2072,\n",
       "         8696,  7619,  2621,  2137,  2035,  5342, 18475,  2049,  1045,\n",
       "        20822,  2052,  1048,  2069,  3401,  4792,  1054, 13612, 12271,\n",
       "         4095,  5204,  2130, 11751, 22097, 22078,  1061, 11796,  1063,\n",
       "         2084,  7751,  2064,  3768,  2058,  2331,  2073,  9541,  4278,\n",
       "         1075,  2755,  4192,  2063, 13636, 12295,  4560,  2491,  1095,\n",
       "         1083, 12414, 13643, 12302,  1100,  9493,  4569,  6540,  2092,\n",
       "         3644,  3715,  2113,  4495,   187]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T09:44:23.246967Z",
     "iopub.status.busy": "2024-11-14T09:44:23.246550Z",
     "iopub.status.idle": "2024-11-14T09:44:23.254167Z",
     "shell.execute_reply": "2024-11-14T09:44:23.253218Z",
     "shell.execute_reply.started": "2024-11-14T09:44:23.246921Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  101,  2055,  2005, 16944,  3370, 10846, 15786,  1036,   110,\n",
       "        16950,  3376, 10852, 15792,  2016,  2010,  3233,  2013,  8667,\n",
       "         3019,  1029,  6145,  1031,  2020,  3477,  2037,  3642,  4517,\n",
       "         1037, 11961,  1039,  2060,  4084,  1044,  2155, 16975, 19356,\n",
       "         8720,  2052,  2826,  6653,  2040,  3270,  1052, 11520,  1054,\n",
       "         2075,  6079,  7638,  2640,  1059,  4704, 25536,  2821,  1063,\n",
       "         2084, 23272,  3727,  2506,  3194,  1071,  3205,  6238,  2483,\n",
       "         1087,  1075,  2962,  3102,  1091,  8718,  2966, 11179,  2069,\n",
       "         3023,  1085,  1085,  4721,  3112,  1101, 12407,  5176,  2091,\n",
       "        12232, 24810, 19749,  6990,   187],\n",
       "       [  101,  2055,  2005, 15454,  8063,  1034,   108, 15458,  8067,\n",
       "         1019,  2470,  2016, 24403,  4020,  1024,  5233,  2016,  2168,\n",
       "         4025,  2900,  2020,  3447,  7408,  2023,  1061,  3299,  1036,\n",
       "         2924,  1038,  2059,  8271,  1043,  2041,  2036,  2143,  2046,\n",
       "        17893,  2037,  8992,  2990,  1050,  8686,  2048,  5241,  1054,\n",
       "         2075,  4099,  3048,  1060,  4176,  2047, 15502,  8111,  2474,\n",
       "         1078,  1066, 18247,  1081,  2057, 26028,  3514,  2059, 28086,\n",
       "         1075,  1075, 16318,  1090,  3726,  9242,  2477,  6195,  1083,\n",
       "         1083, 23518,  5268,  1099, 17406,  2081, 11554,  4086,  2101,\n",
       "         8197, 24473, 18176,  2099,   187],\n",
       "       [  101,  2055,  2005, 13572, 12231,  1034,   108, 13576, 12235,\n",
       "         2012,  1047,  2839,  2009, 16954, 19335,  8699,  2089, 17874,\n",
       "        17745, 18636,  3706, 11497, 11444,  2023,  7601,  3658,  2072,\n",
       "         8696,  7619,  2621,  2137,  2035,  5342, 18475,  2049,  1045,\n",
       "        20822,  2052,  1048,  2069,  3401,  4792,  1054, 13612, 12271,\n",
       "         4095,  5204,  2130, 11751, 22097, 22078,  1061, 11796,  1063,\n",
       "         2084,  7751,  2064,  3768,  2058,  2331,  2073,  9541,  4278,\n",
       "         1075,  2755,  4192,  2063, 13636, 12295,  4560,  2491,  1095,\n",
       "         1083, 12414, 13643, 12302,  1100,  9493,  4569,  6540,  2092,\n",
       "         3644,  3715,  2113,  4495,   187]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EMBEDDINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Architecture](data:image/jpeg;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Token embeddings are generated by mapping discrete token IDs from a vocabulary to dense vector representations using an embedding layer, allowing models to work with numerical representations of the tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T09:44:36.104811Z",
     "iopub.status.busy": "2024-11-14T09:44:36.103957Z",
     "iopub.status.idle": "2024-11-14T09:44:36.340532Z",
     "shell.execute_reply": "2024-11-14T09:44:36.339623Z",
     "shell.execute_reply.started": "2024-11-14T09:44:36.104768Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Embeddings Shape: torch.Size([3, 86, 768])\n",
      "\n",
      "Token Embeddings for Sentence:\n",
      " 0 tensor([[-0.3862,  0.8642, -0.0488,  ..., -0.6794,  0.2618,  1.6389],\n",
      "        [-0.4664, -1.3155,  1.6767,  ...,  2.6758,  0.9058, -0.5537],\n",
      "        [-0.6809,  0.2599,  1.1684,  ..., -0.6493,  2.5284,  0.9133],\n",
      "        ...,\n",
      "        [-0.6969,  0.1508,  1.7230,  ..., -1.1613,  1.1818,  0.3194],\n",
      "        [-0.1261, -1.5120, -0.3148,  ...,  2.1631, -0.1121, -0.4161],\n",
      "        [ 0.7839,  1.4038, -0.5634,  ..., -0.9454, -1.2755,  1.8640]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Shape of the tensor:  torch.Size([86, 768])\n",
      "***************************************************************8\n",
      "\n",
      "Token Embeddings for Sentence:\n",
      " 1 tensor([[-0.3862,  0.8642, -0.0488,  ..., -0.6794,  0.2618,  1.6389],\n",
      "        [-0.4664, -1.3155,  1.6767,  ...,  2.6758,  0.9058, -0.5537],\n",
      "        [-0.6809,  0.2599,  1.1684,  ..., -0.6493,  2.5284,  0.9133],\n",
      "        ...,\n",
      "        [-1.9298, -1.9715,  0.0097,  ..., -1.1668, -0.1471, -0.4609],\n",
      "        [-0.8288,  1.4776, -0.0754,  ...,  0.4653, -0.1705,  0.6525],\n",
      "        [ 0.7839,  1.4038, -0.5634,  ..., -0.9454, -1.2755,  1.8640]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Shape of the tensor:  torch.Size([86, 768])\n",
      "***************************************************************8\n",
      "\n",
      "Token Embeddings for Sentence:\n",
      " 2 tensor([[-0.3862,  0.8642, -0.0488,  ..., -0.6794,  0.2618,  1.6389],\n",
      "        [-0.4664, -1.3155,  1.6767,  ...,  2.6758,  0.9058, -0.5537],\n",
      "        [-0.6809,  0.2599,  1.1684,  ..., -0.6493,  2.5284,  0.9133],\n",
      "        ...,\n",
      "        [-1.3482,  1.0502, -0.1152,  ...,  0.4831, -1.0509,  1.0155],\n",
      "        [ 0.7553, -0.6793,  2.5208,  ..., -1.1215, -0.4714, -1.5207],\n",
      "        [ 0.7839,  1.4038, -0.5634,  ..., -0.9454, -1.2755,  1.8640]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Shape of the tensor:  torch.Size([86, 768])\n",
      "***************************************************************8\n",
      "Final Token Embeddings Shape: \n",
      " torch.Size([3, 86, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def generate_token_embeddings(token_ids, vocab_size, hidden_size):\n",
    "   \n",
    "    embedding_layer = nn.Embedding(vocab_size, hidden_size)\n",
    "\n",
    "    \n",
    "    token_tensor = torch.nn.utils.rnn.pad_sequence(\n",
    "        [torch.tensor(tokens) for tokens in token_ids],\n",
    "        batch_first=True\n",
    "    )\n",
    "\n",
    "\n",
    "    embeddings = embedding_layer(token_tensor)\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "vocab_size = 30522\n",
    "hidden_size = 768\n",
    "\n",
    "token_embeddings = generate_token_embeddings(TOKEN_IDS, vocab_size, hidden_size)\n",
    "\n",
    "print(\"Token Embeddings Shape:\", token_embeddings.shape)  \n",
    "\n",
    "for i in range(len(long_sentences)):\n",
    "    print(\"\\nToken Embeddings for Sentence:\\n\",i, token_embeddings[i])\n",
    "    print(\"Shape of the tensor: \",token_embeddings[i].shape)\n",
    "    print(\"***************************************************************8\")\n",
    "    \n",
    "print(\"Final Token Embeddings Shape: \\n\",token_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positional Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positional embeddings are generated by creating a fixed-size embedding for each position in the input sequence,  to provide information about the relative or absolute position of tokens, allowing the model to capture the order of the tokens in a sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T09:45:09.572440Z",
     "iopub.status.busy": "2024-11-14T09:45:09.571665Z",
     "iopub.status.idle": "2024-11-14T09:45:09.585209Z",
     "shell.execute_reply": "2024-11-14T09:45:09.584142Z",
     "shell.execute_reply.started": "2024-11-14T09:45:09.572401Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positional Embeddings: tensor([[-1.5874e+00,  2.2437e+00,  9.6919e-01,  ...,  9.2780e-01,\n",
      "          6.1042e-01, -9.5628e-01],\n",
      "        [-2.1161e-01,  3.7248e-02,  1.7416e-01,  ..., -1.2033e+00,\n",
      "          2.5375e-01, -1.5684e+00],\n",
      "        [-1.8311e-03,  1.0172e+00,  1.2379e+00,  ...,  7.6410e-01,\n",
      "         -1.0544e+00, -3.1783e-02],\n",
      "        ...,\n",
      "        [-2.8942e-01,  4.2812e-01,  3.7082e-02,  ...,  8.0340e-01,\n",
      "         -5.4609e-01,  5.8625e-01],\n",
      "        [-7.4440e-01,  4.5932e-01, -2.8914e-01,  ...,  1.4828e-01,\n",
      "         -3.1599e-01, -4.5123e-01],\n",
      "        [-3.1164e-01,  5.3895e-01,  1.8928e-01,  ..., -8.2956e-01,\n",
      "         -6.5169e-01,  1.3164e+00]], grad_fn=<SelectBackward0>)\n",
      "Shape:  torch.Size([86, 768])\n",
      "********************************************************************\n",
      "\n",
      "Positional Embeddings: tensor([[-1.5874e+00,  2.2437e+00,  9.6919e-01,  ...,  9.2780e-01,\n",
      "          6.1042e-01, -9.5628e-01],\n",
      "        [-2.1161e-01,  3.7248e-02,  1.7416e-01,  ..., -1.2033e+00,\n",
      "          2.5375e-01, -1.5684e+00],\n",
      "        [-1.8311e-03,  1.0172e+00,  1.2379e+00,  ...,  7.6410e-01,\n",
      "         -1.0544e+00, -3.1783e-02],\n",
      "        ...,\n",
      "        [-2.8942e-01,  4.2812e-01,  3.7082e-02,  ...,  8.0340e-01,\n",
      "         -5.4609e-01,  5.8625e-01],\n",
      "        [-7.4440e-01,  4.5932e-01, -2.8914e-01,  ...,  1.4828e-01,\n",
      "         -3.1599e-01, -4.5123e-01],\n",
      "        [-3.1164e-01,  5.3895e-01,  1.8928e-01,  ..., -8.2956e-01,\n",
      "         -6.5169e-01,  1.3164e+00]], grad_fn=<SelectBackward0>)\n",
      "Shape:  torch.Size([86, 768])\n",
      "********************************************************************\n",
      "\n",
      "Positional Embeddings: tensor([[-1.5874e+00,  2.2437e+00,  9.6919e-01,  ...,  9.2780e-01,\n",
      "          6.1042e-01, -9.5628e-01],\n",
      "        [-2.1161e-01,  3.7248e-02,  1.7416e-01,  ..., -1.2033e+00,\n",
      "          2.5375e-01, -1.5684e+00],\n",
      "        [-1.8311e-03,  1.0172e+00,  1.2379e+00,  ...,  7.6410e-01,\n",
      "         -1.0544e+00, -3.1783e-02],\n",
      "        ...,\n",
      "        [-2.8942e-01,  4.2812e-01,  3.7082e-02,  ...,  8.0340e-01,\n",
      "         -5.4609e-01,  5.8625e-01],\n",
      "        [-7.4440e-01,  4.5932e-01, -2.8914e-01,  ...,  1.4828e-01,\n",
      "         -3.1599e-01, -4.5123e-01],\n",
      "        [-3.1164e-01,  5.3895e-01,  1.8928e-01,  ..., -8.2956e-01,\n",
      "         -6.5169e-01,  1.3164e+00]], grad_fn=<SelectBackward0>)\n",
      "Shape:  torch.Size([86, 768])\n",
      "********************************************************************\n",
      "\n",
      "\n",
      "Final Positional Embeddings Shape:\n",
      " torch.Size([3, 86, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def generate_positional_embeddings(batch_size, max_length, hidden_size):\n",
    "    positional_embeddings = nn.Embedding(max_length, hidden_size)\n",
    "    positional_ids = torch.arange(max_length)\n",
    "    embeddings = positional_embeddings(positional_ids)\n",
    "    positional_embeddings_with_batch = embeddings.unsqueeze(0).expand(batch_size, -1, -1)\n",
    "    return positional_embeddings_with_batch\n",
    "\n",
    "batch_size = 3\n",
    "max_length = 86\n",
    "hidden_size = 768  \n",
    "\n",
    "positional_embeddings = generate_positional_embeddings(batch_size, max_length, hidden_size)\n",
    "for i in range(batch_size):\n",
    "    print(\"Positional Embeddings:\", positional_embeddings[i])\n",
    "    print(\"Shape: \",positional_embeddings[i].shape)\n",
    "    print(\"********************************************************************\\n\")\n",
    "print(\"\\nFinal Positional Embeddings Shape:\\n\", positional_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segment embeddings are generated by using an embedding layer that assigns a unique dense vector to each segment (or sentence) in the input, typically initialized with two embeddings (for segment IDs 0 and 1) to differentiate between segments in tasks like sentence pair classification, allowing the model to distinguish which tokens belong to which segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T09:46:39.927724Z",
     "iopub.status.busy": "2024-11-14T09:46:39.927346Z",
     "iopub.status.idle": "2024-11-14T09:46:39.940511Z",
     "shell.execute_reply": "2024-11-14T09:46:39.939659Z",
     "shell.execute_reply.started": "2024-11-14T09:46:39.927689Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment Embedding:  tensor([[ 0.6940,  0.8967, -0.5143,  ...,  0.8052, -1.7212, -0.7802],\n",
      "        [ 0.6940,  0.8967, -0.5143,  ...,  0.8052, -1.7212, -0.7802],\n",
      "        [ 0.6940,  0.8967, -0.5143,  ...,  0.8052, -1.7212, -0.7802],\n",
      "        ...,\n",
      "        [-1.2047,  1.7846, -0.7213,  ..., -0.9345,  0.4499,  0.2188],\n",
      "        [-1.2047,  1.7846, -0.7213,  ..., -0.9345,  0.4499,  0.2188],\n",
      "        [-1.2047,  1.7846, -0.7213,  ..., -0.9345,  0.4499,  0.2188]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Shape:  torch.Size([86, 768])\n",
      "***************************************************************************\n",
      "Segment Embedding:  tensor([[ 0.6940,  0.8967, -0.5143,  ...,  0.8052, -1.7212, -0.7802],\n",
      "        [ 0.6940,  0.8967, -0.5143,  ...,  0.8052, -1.7212, -0.7802],\n",
      "        [ 0.6940,  0.8967, -0.5143,  ...,  0.8052, -1.7212, -0.7802],\n",
      "        ...,\n",
      "        [-1.2047,  1.7846, -0.7213,  ..., -0.9345,  0.4499,  0.2188],\n",
      "        [-1.2047,  1.7846, -0.7213,  ..., -0.9345,  0.4499,  0.2188],\n",
      "        [-1.2047,  1.7846, -0.7213,  ..., -0.9345,  0.4499,  0.2188]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Shape:  torch.Size([86, 768])\n",
      "***************************************************************************\n",
      "Segment Embedding:  tensor([[ 0.6940,  0.8967, -0.5143,  ...,  0.8052, -1.7212, -0.7802],\n",
      "        [ 0.6940,  0.8967, -0.5143,  ...,  0.8052, -1.7212, -0.7802],\n",
      "        [ 0.6940,  0.8967, -0.5143,  ...,  0.8052, -1.7212, -0.7802],\n",
      "        ...,\n",
      "        [-1.2047,  1.7846, -0.7213,  ..., -0.9345,  0.4499,  0.2188],\n",
      "        [-1.2047,  1.7846, -0.7213,  ..., -0.9345,  0.4499,  0.2188],\n",
      "        [-1.2047,  1.7846, -0.7213,  ..., -0.9345,  0.4499,  0.2188]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Shape:  torch.Size([86, 768])\n",
      "***************************************************************************\n",
      "\n",
      "Final Segment Embeddings:\n",
      " torch.Size([3, 86, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def generate_segment_embeddings(segment_ids, hidden_size):\n",
    "    # Create an embedding layer for two segments (0 and 1)\n",
    "    segment_embeddings = nn.Embedding(2, hidden_size)\n",
    "    \n",
    "    # Get the segment embeddings using the segment IDs\n",
    "    embeddings = segment_embeddings(segment_ids)\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "# Example parameters\n",
    "batch_size = 3\n",
    "max_length = 86\n",
    "hidden_size = 768  \n",
    "\n",
    "# Example segment IDs: a tensor of shape (batch_size, max_length)\n",
    "# Here, the first half is segment 0 and the second half is segment 1\n",
    "SEGMENT_IDS = torch.zeros((batch_size, max_length), dtype=torch.long)\n",
    "SEGMENT_IDS[:, max_length // 2:] = 1\n",
    "\n",
    "# Generate segment embeddings\n",
    "segment_embeddings = generate_segment_embeddings(SEGMENT_IDS, hidden_size)\n",
    "for i in range(batch_size):\n",
    "    print(\"Segment Embedding: \",segment_embeddings[i])\n",
    "    print(\"Shape: \",segment_embeddings[i].shape)\n",
    "    print(\"***************************************************************************\")\n",
    "# Output shape and embeddingsape:\", segment_embeddings.shape)  # Should be (batch_size, max_length, hidden_size)\n",
    "print(\"\\nFinal Segment Embeddings:\\n\", segment_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T09:45:37.878464Z",
     "iopub.status.busy": "2024-11-14T09:45:37.877608Z",
     "iopub.status.idle": "2024-11-14T09:45:37.882556Z",
     "shell.execute_reply": "2024-11-14T09:45:37.881410Z",
     "shell.execute_reply.started": "2024-11-14T09:45:37.878423Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# import random\n",
    "# segment_embedding_1 = torch.rand((36, 768))\n",
    "# segment_embedding_2 = torch.rand((36, 768))\n",
    "\n",
    "# cosine_similarity = F.cosine_similarity(segment_embedding_1, segment_embedding_2)\n",
    "\n",
    "# print(\"Cosine Similarity:\", cosine_similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T09:45:45.708297Z",
     "iopub.status.busy": "2024-11-14T09:45:45.707448Z",
     "iopub.status.idle": "2024-11-14T09:45:45.714631Z",
     "shell.execute_reply": "2024-11-14T09:45:45.713603Z",
     "shell.execute_reply.started": "2024-11-14T09:45:45.708255Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 86, 768])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_embeddings=token_embeddings+positional_embeddings\n",
    "combined_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T09:45:48.552738Z",
     "iopub.status.busy": "2024-11-14T09:45:48.552345Z",
     "iopub.status.idle": "2024-11-14T09:45:48.564827Z",
     "shell.execute_reply": "2024-11-14T09:45:48.563841Z",
     "shell.execute_reply.started": "2024-11-14T09:45:48.552701Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.9736,  3.1079,  0.9204,  ...,  0.2484,  0.8722,  0.6827],\n",
       "         [-0.6780, -1.2783,  1.8509,  ...,  1.4724,  1.1595, -2.1221],\n",
       "         [-0.6827,  1.2771,  2.4063,  ...,  0.1148,  1.4741,  0.8816],\n",
       "         ...,\n",
       "         [-0.9863,  0.5789,  1.7600,  ..., -0.3579,  0.6357,  0.9057],\n",
       "         [-0.8705, -1.0527, -0.6040,  ...,  2.3114, -0.4281, -0.8673],\n",
       "         [ 0.4723,  1.9428, -0.3741,  ..., -1.7750, -1.9272,  3.1804]],\n",
       "\n",
       "        [[-1.9736,  3.1079,  0.9204,  ...,  0.2484,  0.8722,  0.6827],\n",
       "         [-0.6780, -1.2783,  1.8509,  ...,  1.4724,  1.1595, -2.1221],\n",
       "         [-0.6827,  1.2771,  2.4063,  ...,  0.1148,  1.4741,  0.8816],\n",
       "         ...,\n",
       "         [-2.2192, -1.5434,  0.0468,  ..., -0.3634, -0.6932,  0.1254],\n",
       "         [-1.5732,  1.9369, -0.3645,  ...,  0.6136, -0.4865,  0.2013],\n",
       "         [ 0.4723,  1.9428, -0.3741,  ..., -1.7750, -1.9272,  3.1804]],\n",
       "\n",
       "        [[-1.9736,  3.1079,  0.9204,  ...,  0.2484,  0.8722,  0.6827],\n",
       "         [-0.6780, -1.2783,  1.8509,  ...,  1.4724,  1.1595, -2.1221],\n",
       "         [-0.6827,  1.2771,  2.4063,  ...,  0.1148,  1.4741,  0.8816],\n",
       "         ...,\n",
       "         [-1.6376,  1.4783, -0.0781,  ...,  1.2865, -1.5970,  1.6017],\n",
       "         [ 0.0109, -0.2200,  2.2317,  ..., -0.9732, -0.7874, -1.9719],\n",
       "         [ 0.4723,  1.9428, -0.3741,  ..., -1.7750, -1.9272,  3.1804]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T09:46:00.313925Z",
     "iopub.status.busy": "2024-11-14T09:46:00.313310Z",
     "iopub.status.idle": "2024-11-14T09:46:00.336592Z",
     "shell.execute_reply": "2024-11-14T09:46:00.335818Z",
     "shell.execute_reply.started": "2024-11-14T09:46:00.313856Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Mask Shape: torch.Size([3, 86])\n",
      "Attention Mask:\n",
      " tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def generate_attention_mask(combined_embeddings):\n",
    "    batch_size, max_length, _ = combined_embeddings.shape\n",
    "    \n",
    "    attention_mask = (combined_embeddings != 0).any(dim=-1).long()\n",
    "    \n",
    "    return attention_mask\n",
    "\n",
    "batch_size = 3\n",
    "max_length = 86\n",
    "hidden_size = 768\n",
    "\n",
    "\n",
    "combined_embeddings = torch.rand((batch_size, max_length, hidden_size))  \n",
    "\n",
    "attention_mask = generate_attention_mask(combined_embeddings)\n",
    "\n",
    "\n",
    "print(\"Attention Mask Shape:\", attention_mask.shape)  \n",
    "print(\"Attention Mask:\\n\", attention_mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Input Preparation\n",
    "### Input Tensor: The input to the multi-head attention layer is a tensor of shape (batch_size, seq_length, hidden_size), where:\n",
    "### batch_size is the number of input sequences processed simultaneously.\n",
    "### seq_length is the length of each input sequence (number of tokens).\n",
    "### hidden_size is the dimensionality of each token's embedding.\n",
    "\n",
    "## 2. Linear Transformations\n",
    "### Linear Layers: Three separate linear transformations are applied to the input tensor to produce the queries, keys, and values:\n",
    "### Queries: Generated by passing the input through a linear layer designed for queries.\n",
    "### Keys: Generated by passing the input through a linear layer designed for keys.\n",
    "### Values: Generated by passing the input through a linear layer designed for values.\n",
    "\n",
    "## 3. Shape of Queries, Keys, and Values\n",
    "### After the linear transformations, the shapes of the resulting matrices are:\n",
    "### Queries Matrix: (batch_size, seq_length, hidden_size)\n",
    "### Keys Matrix: (batch_size, seq_length, hidden_size)\n",
    "### Values Matrix: (batch_size, seq_length, hidden_size)\n",
    "\n",
    "## 4. Reshaping for Multi-Head Attention\n",
    "### Multi-Head Reshaping: Each of the queries, keys, and values matrices is reshaped to allow for multi-head attention:\n",
    "### The matrices are reshaped to (batch_size, num_heads, seq_length, head_dim), where:\n",
    "### head_dim = hidden_size / num_heads\n",
    "### This involves splitting the hidden_size dimension into multiple heads, enabling the model to learn different representations in parallel.\n",
    "\n",
    "## 5. Output of the Transformation\n",
    "# # 1. ### Final Output: The resulting queries, keys, and values matrices are used in the attention computation. Each matrix retains the context of the input sequences while allowing the model to focus on different parts of the input through attention scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.researchgate.net/publication/366985717/figure/fig4/AS:11431281112323043@1673383393149/Scaled-Dot-Product-Attention-mapping-a-query-and-a-set-of-key-value-pairs-to-an-output.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T09:47:02.434099Z",
     "iopub.status.busy": "2024-11-14T09:47:02.433607Z",
     "iopub.status.idle": "2024-11-14T09:47:02.501495Z",
     "shell.execute_reply": "2024-11-14T09:47:02.500639Z",
     "shell.execute_reply.started": "2024-11-14T09:47:02.434048Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Queries Matrix:-  tensor([[[-0.3336, -0.1104, -0.2010,  ..., -0.2343, -0.0254,  0.1414],\n",
      "         [ 0.0008, -0.2280, -0.2320,  ..., -0.1128,  0.2139, -0.3328],\n",
      "         [ 0.3296, -0.2544, -0.5903,  ..., -0.3380, -0.2704, -0.1561],\n",
      "         ...,\n",
      "         [-0.0467, -0.4404, -0.0532,  ..., -0.3379,  0.0445,  0.0274],\n",
      "         [ 0.0643, -0.0893, -0.3703,  ...,  0.0108,  0.1733, -0.3173],\n",
      "         [ 0.2845, -0.5920, -0.2714,  ..., -0.0694, -0.1482, -0.1905]],\n",
      "\n",
      "        [[ 0.1591, -0.3033, -0.5335,  ..., -0.2954,  0.1675,  0.1684],\n",
      "         [ 0.0653, -0.3028, -0.2386,  ..., -0.2216,  0.0151, -0.1350],\n",
      "         [ 0.1038, -0.1322, -0.3088,  ..., -0.2952,  0.4910, -0.2578],\n",
      "         ...,\n",
      "         [-0.0283, -0.5846, -0.3335,  ..., -0.3694,  0.0342, -0.0603],\n",
      "         [-0.2569, -0.3152, -0.0657,  ..., -0.1171, -0.0591, -0.0359],\n",
      "         [ 0.2843, -0.1372, -0.1578,  ..., -0.2653,  0.3191,  0.0614]],\n",
      "\n",
      "        [[ 0.0930, -0.0384, -0.2212,  ..., -0.4458, -0.0365, -0.0128],\n",
      "         [ 0.0502, -0.0415, -0.1802,  ...,  0.0032, -0.0203, -0.0718],\n",
      "         [-0.0489, -0.2598, -0.1542,  ...,  0.0299,  0.1751, -0.3796],\n",
      "         ...,\n",
      "         [ 0.2920, -0.1876, -0.0628,  ...,  0.0342,  0.1867, -0.1532],\n",
      "         [-0.1147, -0.1891,  0.0325,  ..., -0.0815,  0.4086, -0.1777],\n",
      "         [ 0.1720, -0.2356, -0.0741,  ..., -0.1535,  0.0061, -0.2422]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "Queries Matrix Shape: torch.Size([3, 86, 768])\n",
      "\n",
      "Keys Matrix:-  tensor([[[ 0.3715,  0.0094, -0.7735,  ..., -0.2691, -0.0037, -0.3370],\n",
      "         [ 0.2990,  0.3369, -0.4633,  ..., -0.2154,  0.0577, -0.2034],\n",
      "         [-0.1443,  0.1824, -0.7639,  ...,  0.0713,  0.1807, -0.3745],\n",
      "         ...,\n",
      "         [ 0.2246,  0.0096, -0.6108,  ..., -0.1591,  0.2502,  0.0105],\n",
      "         [-0.1780, -0.2506, -0.3094,  ..., -0.1990,  0.0156, -0.0414],\n",
      "         [ 0.4321,  0.3786, -0.5384,  ..., -0.3270,  0.2888,  0.0830]],\n",
      "\n",
      "        [[ 0.1166, -0.0024, -0.0561,  ..., -0.3009,  0.1852, -0.2568],\n",
      "         [ 0.1616, -0.2202, -0.3563,  ..., -0.5550,  0.0391, -0.0967],\n",
      "         [ 0.0896,  0.0272, -0.4112,  ..., -0.2251,  0.1986, -0.4758],\n",
      "         ...,\n",
      "         [ 0.3353, -0.0131, -0.5252,  ..., -0.4170,  0.1710, -0.1401],\n",
      "         [ 0.1811,  0.0146, -0.8051,  ..., -0.0192,  0.3366, -0.2089],\n",
      "         [ 0.0681, -0.0460, -0.6029,  ..., -0.2879,  0.2887, -0.2387]],\n",
      "\n",
      "        [[ 0.0742,  0.2051, -0.4130,  ...,  0.0868,  0.4218,  0.2296],\n",
      "         [ 0.1621, -0.2063, -0.4536,  ..., -0.8627,  0.3323,  0.0102],\n",
      "         [ 0.2406,  0.0421, -0.5584,  ..., -0.2347,  0.1400,  0.0928],\n",
      "         ...,\n",
      "         [ 0.2863, -0.2731, -0.4889,  ..., -0.1638,  0.2014, -0.2978],\n",
      "         [ 0.1546,  0.1317, -0.7293,  ...,  0.1955,  0.2187, -0.0338],\n",
      "         [ 0.1803,  0.2306, -0.4690,  ..., -0.2884,  0.3122,  0.0837]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "Keys Matrix Shape: torch.Size([3, 86, 768])\n",
      "\n",
      "Values Matrix:-  tensor([[[ 0.5451,  0.3983,  0.0056,  ..., -0.3948,  0.3891, -0.4163],\n",
      "         [ 0.2100,  0.0634,  0.1837,  ..., -0.6815,  0.0450, -0.4869],\n",
      "         [ 0.1707,  0.1344, -0.0085,  ..., -0.6225,  0.2460, -0.2444],\n",
      "         ...,\n",
      "         [ 0.3172,  0.3998, -0.0415,  ..., -0.3921,  0.1730, -0.0882],\n",
      "         [ 0.4170,  0.1460, -0.1641,  ..., -0.2234,  0.5790, -0.2880],\n",
      "         [ 0.2514,  0.1149, -0.3847,  ..., -0.2950,  0.2192, -0.4128]],\n",
      "\n",
      "        [[-0.1837,  0.0189, -0.1495,  ..., -0.2621,  0.2261, -0.2304],\n",
      "         [-0.0565,  0.1317, -0.0632,  ..., -0.3290,  0.1591, -0.2775],\n",
      "         [ 0.2290,  0.1607, -0.1173,  ..., -0.1404,  0.0678, -0.2902],\n",
      "         ...,\n",
      "         [ 0.0980,  0.0155, -0.2533,  ..., -0.3996,  0.0873, -0.4896],\n",
      "         [ 0.3621,  0.1415, -0.0009,  ..., -0.6939,  0.4850, -0.3856],\n",
      "         [ 0.4767,  0.2050, -0.2242,  ..., -0.2112,  0.0628, -0.2129]],\n",
      "\n",
      "        [[ 0.1303,  0.0587, -0.1249,  ..., -0.5785,  0.0964, -0.3311],\n",
      "         [ 0.4283,  0.2568, -0.1100,  ..., -0.7140,  0.3148, -0.0772],\n",
      "         [-0.0107,  0.1573, -0.0601,  ..., -0.5582, -0.0837, -0.1670],\n",
      "         ...,\n",
      "         [-0.1422,  0.3788, -0.0245,  ..., -0.7391,  0.3110, -0.2256],\n",
      "         [ 0.4173, -0.2497, -0.1345,  ..., -0.6276,  0.3327, -0.1274],\n",
      "         [ 0.1722,  0.1198, -0.1772,  ..., -0.3483,  0.1997, -0.1379]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "Values Matrix Shape: torch.Size([3, 86, 768])\n",
      "Attention scores shape:  torch.Size([3, 12, 86, 86])\n",
      "Attention score shape after softmax:  torch.Size([3, 12, 86, 86])\n",
      "Output Embeddings Shape: torch.Size([3, 86, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, hidden_size, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = hidden_size // num_heads\n",
    "\n",
    "        assert (\n",
    "            hidden_size % num_heads == 0\n",
    "        ), \"hidden_size must be divisible by num_heads\"\n",
    "\n",
    "        self.query_linear = nn.Linear(hidden_size, hidden_size)\n",
    "        self.key_linear = nn.Linear(hidden_size, hidden_size)\n",
    "        self.value_linear = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc_out = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_length, hidden_size = x.size()\n",
    "\n",
    "        queries = self.query_linear(x)  \n",
    "        keys = self.key_linear(x)\n",
    "        values = self.value_linear(x)\n",
    "\n",
    "        # Print the query, key, and value matrices\n",
    "        print(\"\\nQueries Matrix:- \",queries)\n",
    "        print(\"Queries Matrix Shape:\", queries.shape)\n",
    "        print(\"\\nKeys Matrix:- \",keys)\n",
    "        print(\"Keys Matrix Shape:\", keys.shape)\n",
    "        print(\"\\nValues Matrix:- \",values)\n",
    "        print(\"Values Matrix Shape:\", values.shape)\n",
    "\n",
    "        # Reshape for multi-head attention\n",
    "        queries = queries.view(batch_size, seq_length, self.num_heads, self.head_dim).transpose(1, 2)  # (batch_size, num_heads, seq_length, head_dim)\n",
    "        keys = keys.view(batch_size, seq_length, self.num_heads, self.head_dim).transpose(1, 2)  # (batch_size, num_heads, seq_length, head_dim)\n",
    "        values = values.view(batch_size, seq_length, self.num_heads, self.head_dim).transpose(1, 2)  # (batch_size, num_heads, seq_length, head_dim)\n",
    "        energy = torch.einsum(\"nhqd,nhkd->nhqk\", [queries, keys])  # (batch_size, num_heads, seq_length, seq_length)\n",
    "\n",
    "        attention_scores = energy / (self.head_dim ** 0.5)\n",
    "        print(\"Attention scores shape: \",attention_scores.shape)\n",
    "        attention = torch.softmax(energy / (self.head_dim ** 0.5), dim=3)  # Scale and softmax\n",
    "        print(\"Attention score shape after softmax: \",attention.shape)\n",
    "        out = torch.einsum(\"nhql,nhld->nhqd\", [attention, values]).reshape(batch_size, seq_length, hidden_size)  # (batch_size, seq_length, hidden_size)\n",
    "        out = self.fc_out(out)  # Final linear layer\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "batch_size = 3\n",
    "seq_length = 86\n",
    "hidden_size = 768\n",
    "num_heads = 12\n",
    "\n",
    "attention_layer = MultiHeadAttention(hidden_size, num_heads)\n",
    "\n",
    "\n",
    "combined_embeddings = combined_embeddings\n",
    "\n",
    "\n",
    "output_embeddings = attention_layer(combined_embeddings)\n",
    "\n",
    "print(\"Output Embeddings Shape:\", output_embeddings.shape)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T09:47:19.620416Z",
     "iopub.status.busy": "2024-11-14T09:47:19.619709Z",
     "iopub.status.idle": "2024-11-14T09:47:19.629727Z",
     "shell.execute_reply": "2024-11-14T09:47:19.628814Z",
     "shell.execute_reply.started": "2024-11-14T09:47:19.620378Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1223, -0.1315, -0.0793,  ..., -0.0535,  0.1185,  0.2093],\n",
       "         [-0.1218, -0.1318, -0.0797,  ..., -0.0533,  0.1186,  0.2090],\n",
       "         [-0.1218, -0.1321, -0.0791,  ..., -0.0535,  0.1188,  0.2091],\n",
       "         ...,\n",
       "         [-0.2159, -0.4870, -0.3054,  ...,  0.0545, -0.1449,  0.1685],\n",
       "         [-0.2156, -0.4871, -0.3056,  ...,  0.0541, -0.1447,  0.1683],\n",
       "         [-0.2159, -0.4875, -0.3049,  ...,  0.0542, -0.1454,  0.1684]],\n",
       "\n",
       "        [[-0.1150, -0.1093, -0.0672,  ..., -0.0665,  0.1333,  0.2098],\n",
       "         [-0.1143, -0.1092, -0.0671,  ..., -0.0665,  0.1325,  0.2099],\n",
       "         [-0.1148, -0.1088, -0.0672,  ..., -0.0661,  0.1329,  0.2096],\n",
       "         ...,\n",
       "         [-0.2240, -0.4953, -0.3235,  ...,  0.0474, -0.1286,  0.1675],\n",
       "         [-0.2239, -0.4954, -0.3228,  ...,  0.0478, -0.1285,  0.1676],\n",
       "         [-0.2237, -0.4946, -0.3228,  ...,  0.0476, -0.1287,  0.1679]],\n",
       "\n",
       "        [[-0.1231, -0.1265, -0.0677,  ..., -0.0777,  0.1259,  0.2041],\n",
       "         [-0.1232, -0.1270, -0.0674,  ..., -0.0779,  0.1254,  0.2045],\n",
       "         [-0.1230, -0.1265, -0.0678,  ..., -0.0785,  0.1257,  0.2041],\n",
       "         ...,\n",
       "         [-0.2227, -0.4881, -0.3140,  ...,  0.0400, -0.1351,  0.1780],\n",
       "         [-0.2221, -0.4879, -0.3142,  ...,  0.0388, -0.1350,  0.1789],\n",
       "         [-0.2226, -0.4885, -0.3139,  ...,  0.0389, -0.1354,  0.1786]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T09:47:44.403592Z",
     "iopub.status.busy": "2024-11-14T09:47:44.402951Z",
     "iopub.status.idle": "2024-11-14T09:47:44.409595Z",
     "shell.execute_reply": "2024-11-14T09:47:44.408528Z",
     "shell.execute_reply.started": "2024-11-14T09:47:44.403556Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class QAHead(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(QAHead, self).__init__()\n",
    "        self.start_logits = nn.Linear(hidden_size, 1)\n",
    "        self.end_logits = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, embeddings):\n",
    "        start_logits = self.start_logits(embeddings).squeeze(-1)  \n",
    "        end_logits = self.end_logits(embeddings).squeeze(-1)      \n",
    "        return start_logits, end_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T09:47:47.658182Z",
     "iopub.status.busy": "2024-11-14T09:47:47.657353Z",
     "iopub.status.idle": "2024-11-14T09:47:47.664849Z",
     "shell.execute_reply": "2024-11-14T09:47:47.663874Z",
     "shell.execute_reply.started": "2024-11-14T09:47:47.658145Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Logits Shape: torch.Size([3, 86])\n",
      "End Logits Shape: torch.Size([3, 86])\n"
     ]
    }
   ],
   "source": [
    "qa_head = QAHead(hidden_size)\n",
    "start_logits, end_logits = qa_head(output_embeddings)\n",
    "\n",
    "print(\"Start Logits Shape:\", start_logits.shape)  \n",
    "print(\"End Logits Shape:\", end_logits.shape)      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T09:47:53.203479Z",
     "iopub.status.busy": "2024-11-14T09:47:53.202600Z",
     "iopub.status.idle": "2024-11-14T09:47:53.215746Z",
     "shell.execute_reply": "2024-11-14T09:47:53.214706Z",
     "shell.execute_reply.started": "2024-11-14T09:47:53.203439Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 5.1903e-03,  4.9413e-03,  5.1574e-03,  5.0190e-03,  4.4882e-03,\n",
       "           4.7075e-03,  5.0871e-03, -8.9973e-02, -8.3061e-02, -8.3142e-02,\n",
       "          -8.3145e-02, -8.2976e-02, -8.2826e-02, -8.2902e-02,  2.8370e-02,\n",
       "           1.6723e-03,  1.6327e-03,  1.5470e-03,  1.7180e-03,  1.5761e-03,\n",
       "           1.7040e-03,  1.9245e-02, -1.3720e-03, -1.2795e-03, -1.4725e-03,\n",
       "          -1.3292e-03, -1.2763e-03, -1.7393e-03, -5.4750e-02, -3.9511e-02,\n",
       "          -3.9536e-02, -3.9793e-02, -3.9796e-02, -3.9803e-02, -3.9516e-02,\n",
       "          -3.6554e-02, -1.0518e-01, -1.0512e-01, -1.0526e-01, -1.0511e-01,\n",
       "          -1.0507e-01, -1.0496e-01, -1.0537e-01, -1.2840e-01, -1.2825e-01,\n",
       "          -1.2857e-01, -1.2813e-01, -1.2821e-01, -1.2795e-01, -1.2806e-01,\n",
       "          -9.8288e-03, -2.0979e-02, -2.0935e-02, -2.0877e-02, -2.0953e-02,\n",
       "          -2.0963e-02, -2.1035e-02, -3.6352e-02, -4.8528e-02, -4.8573e-02,\n",
       "          -4.8654e-02, -4.8765e-02, -4.8649e-02, -4.8733e-02, -3.4243e-02,\n",
       "          -6.1112e-02, -6.1284e-02, -6.1111e-02, -6.1190e-02, -6.1097e-02,\n",
       "          -6.0881e-02, -5.8807e-02,  3.0979e-02,  3.0563e-02,  3.0828e-02,\n",
       "           3.0637e-02,  3.0998e-02,  3.0392e-02,  6.2304e-02, -5.7693e-02,\n",
       "          -5.8063e-02, -5.7610e-02, -5.7594e-02, -5.7851e-02, -5.7784e-02,\n",
       "          -5.7871e-02],\n",
       "         [-5.2710e-03, -5.1192e-03, -5.4912e-03, -5.0383e-03, -5.2550e-03,\n",
       "          -4.6911e-03, -5.4019e-03, -8.3974e-02, -7.6747e-02, -7.6545e-02,\n",
       "          -7.6940e-02, -7.6737e-02, -7.6590e-02, -7.6536e-02,  2.8635e-02,\n",
       "           3.3648e-03,  3.3245e-03,  3.4247e-03,  3.2691e-03,  3.0834e-03,\n",
       "           3.4682e-03,  2.1970e-02,  6.4632e-03,  6.2657e-03,  6.1346e-03,\n",
       "           5.9316e-03,  6.2746e-03,  6.3297e-03, -4.6000e-02, -3.4097e-02,\n",
       "          -3.4460e-02, -3.4006e-02, -3.3957e-02, -3.3795e-02, -3.3807e-02,\n",
       "          -3.1359e-02, -9.9070e-02, -9.9080e-02, -9.9235e-02, -9.9206e-02,\n",
       "          -9.9076e-02, -9.8990e-02, -9.9162e-02, -1.2381e-01, -1.2332e-01,\n",
       "          -1.2344e-01, -1.2342e-01, -1.2367e-01, -1.2357e-01, -1.2364e-01,\n",
       "          -6.6149e-03, -2.2959e-02, -2.2875e-02, -2.2833e-02, -2.2896e-02,\n",
       "          -2.3193e-02, -2.3179e-02, -4.1056e-02, -4.5946e-02, -4.5986e-02,\n",
       "          -4.6011e-02, -4.5943e-02, -4.6270e-02, -4.6039e-02, -4.8894e-02,\n",
       "          -7.2015e-02, -7.2074e-02, -7.1920e-02, -7.1868e-02, -7.2175e-02,\n",
       "          -7.1848e-02, -5.9223e-02,  3.5450e-02,  3.5657e-02,  3.5768e-02,\n",
       "           3.5499e-02,  3.5859e-02,  3.5650e-02,  6.4815e-02, -5.4733e-02,\n",
       "          -5.4389e-02, -5.4498e-02, -5.4625e-02, -5.4816e-02, -5.4250e-02,\n",
       "          -5.4430e-02],\n",
       "         [-8.4625e-03, -8.3888e-03, -8.4274e-03, -8.3261e-03, -7.9226e-03,\n",
       "          -8.4128e-03, -8.2377e-03, -8.0926e-02, -7.1649e-02, -7.1809e-02,\n",
       "          -7.1615e-02, -7.1706e-02, -7.1730e-02, -7.1646e-02,  2.9235e-02,\n",
       "          -3.3593e-04, -2.5997e-04, -4.3073e-04, -7.3491e-05, -2.8636e-04,\n",
       "          -2.6819e-04,  2.0968e-02,  6.2579e-03,  6.3168e-03,  6.0027e-03,\n",
       "           5.9662e-03,  5.9963e-03,  6.0212e-03, -5.0812e-02, -4.2749e-02,\n",
       "          -4.2971e-02, -4.3122e-02, -4.2625e-02, -4.2760e-02, -4.3081e-02,\n",
       "          -3.7868e-02, -1.0085e-01, -1.0097e-01, -1.0098e-01, -1.0152e-01,\n",
       "          -1.0118e-01, -1.0089e-01, -1.0125e-01, -1.2232e-01, -1.2238e-01,\n",
       "          -1.2216e-01, -1.2242e-01, -1.2238e-01, -1.2213e-01, -1.2239e-01,\n",
       "          -3.4802e-03, -1.5876e-02, -1.6006e-02, -1.6081e-02, -1.5814e-02,\n",
       "          -1.6078e-02, -1.5992e-02, -4.0516e-02, -5.8114e-02, -5.8212e-02,\n",
       "          -5.8184e-02, -5.8407e-02, -5.7995e-02, -5.8111e-02, -5.4561e-02,\n",
       "          -7.4186e-02, -7.4581e-02, -7.4248e-02, -7.4337e-02, -7.4238e-02,\n",
       "          -7.4253e-02, -6.5601e-02,  3.7632e-02,  3.7665e-02,  3.7689e-02,\n",
       "           3.7663e-02,  3.7794e-02,  3.7695e-02,  6.7435e-02, -7.0808e-02,\n",
       "          -7.0650e-02, -7.0964e-02, -7.1103e-02, -7.0818e-02, -7.0923e-02,\n",
       "          -7.0900e-02]], grad_fn=<SqueezeBackward1>),\n",
       " tensor([[-0.0921, -0.0919, -0.0919, -0.0919, -0.0920, -0.0918, -0.0921, -0.0237,\n",
       "          -0.0298, -0.0292, -0.0295, -0.0295, -0.0298, -0.0295,  0.1303,  0.0825,\n",
       "           0.0827,  0.0828,  0.0828,  0.0829,  0.0831, -0.1041, -0.0486, -0.0486,\n",
       "          -0.0488, -0.0486, -0.0486, -0.0487, -0.0205,  0.0499,  0.0499,  0.0499,\n",
       "           0.0497,  0.0500,  0.0499,  0.0331,  0.1068,  0.1063,  0.1060,  0.1065,\n",
       "           0.1063,  0.1065,  0.1063, -0.1423, -0.1422, -0.1422, -0.1421, -0.1424,\n",
       "          -0.1421, -0.1424, -0.1091, -0.0512, -0.0510, -0.0513, -0.0510, -0.0509,\n",
       "          -0.0513, -0.0041,  0.0527,  0.0529,  0.0530,  0.0532,  0.0529,  0.0527,\n",
       "           0.0200, -0.0270, -0.0272, -0.0271, -0.0274, -0.0272, -0.0270, -0.0233,\n",
       "          -0.1641, -0.1646, -0.1641, -0.1643, -0.1643, -0.1646, -0.1107, -0.0069,\n",
       "          -0.0073, -0.0065, -0.0068, -0.0067, -0.0071, -0.0069],\n",
       "         [-0.1041, -0.1032, -0.1035, -0.1036, -0.1039, -0.1037, -0.1038, -0.0155,\n",
       "          -0.0244, -0.0241, -0.0242, -0.0246, -0.0242, -0.0244,  0.1377,  0.0853,\n",
       "           0.0852,  0.0854,  0.0853,  0.0854,  0.0854, -0.1072, -0.0511, -0.0512,\n",
       "          -0.0511, -0.0512, -0.0513, -0.0509, -0.0122,  0.0500,  0.0499,  0.0499,\n",
       "           0.0499,  0.0501,  0.0499,  0.0300,  0.1219,  0.1217,  0.1219,  0.1218,\n",
       "           0.1217,  0.1215,  0.1216, -0.1413, -0.1413, -0.1412, -0.1411, -0.1413,\n",
       "          -0.1411, -0.1411, -0.1044, -0.0486, -0.0486, -0.0484, -0.0487, -0.0487,\n",
       "          -0.0486,  0.0029,  0.0581,  0.0578,  0.0584,  0.0584,  0.0585,  0.0581,\n",
       "           0.0189, -0.0315, -0.0315, -0.0313, -0.0316, -0.0316, -0.0317, -0.0323,\n",
       "          -0.1559, -0.1554, -0.1557, -0.1557, -0.1556, -0.1560, -0.0945, -0.0100,\n",
       "          -0.0102, -0.0100, -0.0101, -0.0099, -0.0100, -0.0099],\n",
       "         [-0.1048, -0.1048, -0.1046, -0.1046, -0.1046, -0.1045, -0.1047, -0.0173,\n",
       "          -0.0248, -0.0249, -0.0250, -0.0250, -0.0247, -0.0249,  0.1401,  0.0845,\n",
       "           0.0847,  0.0848,  0.0844,  0.0847,  0.0846, -0.0973, -0.0399, -0.0397,\n",
       "          -0.0399, -0.0400, -0.0400, -0.0400, -0.0136,  0.0382,  0.0379,  0.0381,\n",
       "           0.0380,  0.0379,  0.0384,  0.0244,  0.1261,  0.1259,  0.1262,  0.1260,\n",
       "           0.1261,  0.1261,  0.1261, -0.1350, -0.1347, -0.1349, -0.1351, -0.1349,\n",
       "          -0.1350, -0.1350, -0.1080, -0.0556, -0.0554, -0.0554, -0.0554, -0.0554,\n",
       "          -0.0554, -0.0049,  0.0593,  0.0599,  0.0595,  0.0597,  0.0597,  0.0599,\n",
       "           0.0266, -0.0206, -0.0207, -0.0205, -0.0208, -0.0207, -0.0205, -0.0217,\n",
       "          -0.1624, -0.1623, -0.1623, -0.1624, -0.1623, -0.1628, -0.1072, -0.0117,\n",
       "          -0.0117, -0.0122, -0.0121, -0.0121, -0.0120, -0.0119]],\n",
       "        grad_fn=<SqueezeBackward1>))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_logits,end_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T09:48:19.518077Z",
     "iopub.status.busy": "2024-11-14T09:48:19.517667Z",
     "iopub.status.idle": "2024-11-14T09:48:19.525787Z",
     "shell.execute_reply": "2024-11-14T09:48:19.524950Z",
     "shell.execute_reply.started": "2024-11-14T09:48:19.518038Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([78, 78, 78]), tensor([14, 14, 14]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_positions = torch.argmax(start_logits, dim=-1)\n",
    "end_positions = torch.argmax(end_logits, dim=-1)\n",
    "start_positions,end_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T09:58:39.677737Z",
     "iopub.status.busy": "2024-11-14T09:58:39.676781Z",
     "iopub.status.idle": "2024-11-14T09:58:39.684223Z",
     "shell.execute_reply": "2024-11-14T09:58:39.683140Z",
     "shell.execute_reply.started": "2024-11-14T09:58:39.677693Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1:\n",
      "What is Cybersecurity?\n",
      "\n",
      "Question 1:\n",
      "What is Malware?\n",
      "\n",
      "Question 1:\n",
      "What is Phishing?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx=0\n",
    "for l in long_sentences:\n",
    "    print(\"Question 1:\")\n",
    "    print(l[0])\n",
    "    print(l[1][start_positions[idx]:end_positions[idx]])\n",
    "    idx+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QA Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T09:52:17.292768Z",
     "iopub.status.busy": "2024-11-14T09:52:17.291852Z",
     "iopub.status.idle": "2024-11-14T09:52:17.648393Z",
     "shell.execute_reply": "2024-11-14T09:52:17.647373Z",
     "shell.execute_reply.started": "2024-11-14T09:52:17.292725Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "context = \"Pradyumna Prahas is a Student of KMIT. He is in his BTECH 3rd year.\"\n",
    "question = \"Who is Prahas?\"\n",
    "\n",
    "encoding = tokenizer.encode_plus(question, context, add_special_tokens=True, return_tensors='pt')\n",
    "\n",
    "input_ids = encoding['input_ids']\n",
    "attention_mask = encoding['attention_mask']\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = bert_model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    hidden_states = outputs.last_hidden_state  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T09:52:20.767592Z",
     "iopub.status.busy": "2024-11-14T09:52:20.767217Z",
     "iopub.status.idle": "2024-11-14T09:52:20.781820Z",
     "shell.execute_reply": "2024-11-14T09:52:20.780949Z",
     "shell.execute_reply.started": "2024-11-14T09:52:20.767555Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Queries Matrix:-  tensor([[[-0.2050,  0.2426,  0.1489,  ...,  0.1986,  0.0547,  0.5571],\n",
      "         [ 0.1915,  0.1627,  0.1617,  ...,  0.2853, -0.1960,  0.8077],\n",
      "         [ 0.0266,  0.3304,  0.1861,  ...,  0.0677, -0.3432, -0.1715],\n",
      "         ...,\n",
      "         [ 0.2746, -0.0355,  0.1327,  ...,  0.0956, -0.2296, -0.2023],\n",
      "         [ 0.1610, -0.7086, -0.5655,  ...,  0.0833,  0.0047, -0.4073],\n",
      "         [ 0.1671, -0.8434, -0.4769,  ..., -0.1296,  0.0627, -0.6540]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "Queries Matrix Shape: torch.Size([1, 32, 768])\n",
      "\n",
      "Keys Matrix:-  tensor([[[ 0.4387, -0.4229, -0.2472,  ...,  0.3507, -0.2083,  0.0540],\n",
      "         [-0.0482, -0.2812, -0.4099,  ...,  0.5263,  0.0311, -0.0277],\n",
      "         [ 0.1887,  0.1369, -0.6056,  ..., -0.2040,  0.1899, -0.0975],\n",
      "         ...,\n",
      "         [-0.3792, -0.1769,  0.0531,  ...,  0.1474,  0.6420,  0.1686],\n",
      "         [-0.2234, -0.0999, -0.0329,  ...,  0.1259,  0.2501,  0.3813],\n",
      "         [ 0.0383, -0.1314, -0.0809,  ...,  0.0700,  0.3392,  0.2556]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "Keys Matrix Shape: torch.Size([1, 32, 768])\n",
      "\n",
      "Values Matrix:-  tensor([[[-0.4316, -0.0064, -0.1194,  ...,  0.2959, -0.3267,  0.0250],\n",
      "         [-0.5388, -0.2939, -0.2306,  ...,  0.2492,  0.2620, -0.1225],\n",
      "         [-0.4164,  0.1956, -0.4159,  ..., -0.1032,  0.6229,  0.0225],\n",
      "         ...,\n",
      "         [ 0.2132,  0.1474, -0.2864,  ..., -0.0526, -0.0166,  0.1399],\n",
      "         [-0.0042,  0.0610,  0.5655,  ...,  0.4847,  0.5351, -0.2575],\n",
      "         [ 0.1267,  0.0966,  0.4779,  ...,  0.5389,  0.3728, -0.3802]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "Values Matrix Shape: torch.Size([1, 32, 768])\n",
      "Attention scores shape:  torch.Size([1, 12, 32, 32])\n",
      "Attention score shape after softmax:  torch.Size([1, 12, 32, 32])\n",
      "Start Logits Shape: torch.Size([1, 32])\n",
      "End Logits Shape: torch.Size([1, 32])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output_embeddings = attention_layer(hidden_states)\n",
    "\n",
    "qa_head = QAHead(hidden_size)\n",
    "start_logits, end_logits = qa_head(output_embeddings)\n",
    "\n",
    "print(\"Start Logits Shape:\", start_logits.shape)\n",
    "print(\"End Logits Shape:\", end_logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T09:52:24.427211Z",
     "iopub.status.busy": "2024-11-14T09:52:24.426776Z",
     "iopub.status.idle": "2024-11-14T09:52:24.436681Z",
     "shell.execute_reply": "2024-11-14T09:52:24.435781Z",
     "shell.execute_reply.started": "2024-11-14T09:52:24.427172Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0462, -0.0461, -0.0171, -0.0749, -0.0740,  0.0480,  0.1180,  0.1132,\n",
       "          -0.1754, -0.1738, -0.2079, -0.1763, -0.1764,  0.0099,  0.0083,  0.0099,\n",
       "           0.0584,  0.0596,  0.0426, -0.0276, -0.0286, -0.0303, -0.0068, -0.0038,\n",
       "           0.0421,  0.0406,  0.0718,  0.0641,  0.0627,  0.0389,  0.0814,  0.0825]],\n",
       "        grad_fn=<SqueezeBackward1>),\n",
       " tensor([[-0.0919, -0.0918,  0.0096, -0.0128, -0.0132, -0.0555, -0.0773, -0.0774,\n",
       "          -0.0199, -0.0117, -0.0096, -0.1335, -0.1326, -0.0922, -0.0695, -0.0703,\n",
       "          -0.0971, -0.0986, -0.0150,  0.0866,  0.0868,  0.0019, -0.0095, -0.0090,\n",
       "          -0.0465, -0.0435, -0.0376,  0.0556,  0.0515,  0.0448, -0.0194, -0.0193]],\n",
       "        grad_fn=<SqueezeBackward1>))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_logits, end_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T09:52:26.267270Z",
     "iopub.status.busy": "2024-11-14T09:52:26.266682Z",
     "iopub.status.idle": "2024-11-14T09:52:26.274634Z",
     "shell.execute_reply": "2024-11-14T09:52:26.273781Z",
     "shell.execute_reply.started": "2024-11-14T09:52:26.267232Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 20)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the index of the start and end token with the highest logits\n",
    "start_idx = torch.argmax(start_logits, dim=-1).item()\n",
    "end_idx = torch.argmax(end_logits, dim=-1).item()\n",
    "start_idx,end_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T09:52:33.632120Z",
     "iopub.status.busy": "2024-11-14T09:52:33.631298Z",
     "iopub.status.idle": "2024-11-14T09:52:33.639082Z",
     "shell.execute_reply": "2024-11-14T09:52:33.638165Z",
     "shell.execute_reply.started": "2024-11-14T09:52:33.632081Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Answer: ? pradyumna prahas is a student of kmit\n"
     ]
    }
   ],
   "source": [
    "# # Find the index of the start and end token with the highest logits\n",
    "# start_idx = torch.argmax(start_logits, dim=-1).item()\n",
    "# end_idx = torch.argmax(end_logits, dim=-1).item()\n",
    "\n",
    "# Ensure start_idx <= end_idx (sometimes due to noise, the start index could be after the end index)\n",
    "if start_idx > end_idx:\n",
    "    start_idx, end_idx = end_idx, start_idx\n",
    "\n",
    "# Decode the answer from the token indices\n",
    "predicted_answer_tokens = input_ids[0][start_idx:end_idx + 1]\n",
    "predicted_answer = tokenizer.decode(predicted_answer_tokens, skip_special_tokens=True)\n",
    "\n",
    "print(\"Predicted Answer:\", predicted_answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WORD 2 VEC"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
